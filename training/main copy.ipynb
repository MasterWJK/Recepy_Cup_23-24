{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "#import sweetviz as sv\n",
    "#import shap\n",
    "#from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "seed = 2024  #seed = 2024: train model as stated in example_crisp_dm_pipeline.ipynb\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Data Cleaning: Readin data and preprocessing individual table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75604 entries, 0 to 75603\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   RecipeId              75604 non-null  int64   \n",
      " 1   RecipeCategory        75604 non-null  category\n",
      " 2   Calories              75604 non-null  float64 \n",
      " 3   FatContent            75604 non-null  float64 \n",
      " 4   SaturatedFatContent   75604 non-null  float64 \n",
      " 5   CholesterolContent    75604 non-null  float64 \n",
      " 6   SodiumContent         75604 non-null  float64 \n",
      " 7   CarbohydrateContent   75604 non-null  float64 \n",
      " 8   FiberContent          75604 non-null  float64 \n",
      " 9   SugarContent          75604 non-null  float64 \n",
      " 10  ProteinContent        75604 non-null  float64 \n",
      " 11  RecipeServings        48891 non-null  float64 \n",
      " 12  recipe_diet_category  75604 non-null  category\n",
      " 13  TotalTime_Recipe      75604 non-null  int64   \n",
      "dtypes: category(2), float64(10), int64(2)\n",
      "memory usage: 7.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>RecipeCategory</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SaturatedFatContent</th>\n",
       "      <th>CholesterolContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>FiberContent</th>\n",
       "      <th>SugarContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>RecipeServings</th>\n",
       "      <th>recipe_diet_category</th>\n",
       "      <th>TotalTime_Recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73440</td>\n",
       "      <td>Other</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365718</td>\n",
       "      <td>Other</td>\n",
       "      <td>370.8</td>\n",
       "      <td>17.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>553.3</td>\n",
       "      <td>44.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141757</td>\n",
       "      <td>Other</td>\n",
       "      <td>377.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>45.7</td>\n",
       "      <td>1501.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280351</td>\n",
       "      <td>Other</td>\n",
       "      <td>282.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>50.5</td>\n",
       "      <td>630.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>19800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180505</td>\n",
       "      <td>Other</td>\n",
       "      <td>257.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>110.7</td>\n",
       "      <td>160.9</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>5400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecipeId RecipeCategory  Calories  FatContent  SaturatedFatContent   \n",
       "0     73440          Other     241.3        10.1                  1.2  \\\n",
       "1    365718          Other     370.8        17.5                  7.2   \n",
       "2    141757          Other     377.6        20.9                 10.5   \n",
       "3    280351          Other     282.8        16.5                 10.3   \n",
       "4    180505          Other     257.5         8.6                  2.4   \n",
       "\n",
       "   CholesterolContent  SodiumContent  CarbohydrateContent  FiberContent   \n",
       "0                 0.0           13.1                 31.8           2.3  \\\n",
       "1                22.9          553.3                 44.3           1.6   \n",
       "2                45.7         1501.8                 36.6           3.8   \n",
       "3                50.5          630.2                 22.8           2.3   \n",
       "4               110.7          160.9                 39.8           0.4   \n",
       "\n",
       "   SugarContent  ProteinContent  RecipeServings recipe_diet_category   \n",
       "0           1.4             6.7             9.0           Vegetarian  \\\n",
       "1           2.2             9.4             8.0             Omnivore   \n",
       "2           6.1            12.9             8.0           Vegetarian   \n",
       "3           2.7            11.7             6.0             Omnivore   \n",
       "4          30.2             6.3             6.0                Vegan   \n",
       "\n",
       "   TotalTime_Recipe  \n",
       "0              1800  \n",
       "1              4200  \n",
       "2              6300  \n",
       "3             19800  \n",
       "4              5400  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipes = pd.read_csv('data/recipes.csv')\n",
    "\n",
    "# Consolidated Non-Vegetarian Keywords\n",
    "non_vegetarian_keywords = list(set([\n",
    "    'flounder', 'lobsters', 'lump', 'rack', 'shank', 'steak', 'scallops', 'alligator', \n",
    "    'livers', 'roe', 'ham', 'turkey', 'chicken', 'duck', 'bacon', 'tuna', 'swordfish', \n",
    "    'lobster', 'meatballs', 'salmon', 'sweetbreads', 'breasts', 'chicken-flavored', \n",
    "    'ducklings', 'drumstick', 'liver', 'shanks', 'rabbit', 'poultry', 'herring', \n",
    "    'mussels', 'clams', 'squid', 'pork', 'veal', 'haddock', 'chorizo', 'chihuahua', \n",
    "    'eel', 'stuffing', 'cod', 'gelatin', 'sausage', 'curd', 'thighs', 'lox', 'cabbage', \n",
    "    'wonton', 'bone', 'giblets', 'pheasant', 'quail', 'shrimp', 'fish', 'sole', \n",
    "    'gizzard', 'Canadian', 'pesto', 'truffles', 'anchovies', 'venison', 'pheasants', \n",
    "    'tenderloin', 'meats', 'tripe', 'breast', 'wings', 'ribs', 'sausages', 'trout', \n",
    "    'oysters', 'octopus', 'crab', 'prawns', 'catfish', 'sardines', 'mahi', 'halibut', \n",
    "    'bass', 'perch', 'tilapia', 'grouper'\n",
    "]))\n",
    "\n",
    "# Consolidated Non-Vegan Keywords\n",
    "non_vegan_keywords = list(set([\n",
    "    'milk', 'cheese', 'butter', 'egg', 'honey', 'mozzarella-cheddar', 'cream', 'whip', \n",
    "    'jarlsberg', 'fontina', 'ham', 'cheesecake', 'hollandaise', 'caviar', 'creamRegular', \n",
    "    'custard', 'yogurt', 'gouda', 'margarine', 'beef', 'salmon', 'sour', 'bisquick', \n",
    "    'carton', 'cotija', 'creme', 'buttercream', 'buttermilk', 'ricotta', 'cottage', \n",
    "    'eggs', 'mayonnaise', 'eggshells', 'lactose-free', 'skim', 'ghee', 'mascarpone', \n",
    "    'alfredo', 'whey', 'casein', 'lactose', 'albumin', 'bechamel', 'sour cream', \n",
    "    'cream cheese', 'feta', 'gorgonzola', 'parmesan', 'mozzarella', 'cheddar', 'brie', \n",
    "    'camembert', 'roquefort', 'stilton', 'blue cheese', 'colby', 'monterey jack', \n",
    "    'swiss cheese', 'provolone', 'edam', 'havarti', 'pecorino', 'asiago', 'emmental', \n",
    "    'gruyere', 'halloumi', 'manchego', 'paneer', 'queso fresco', 'ricotta salata', \n",
    "    'romano', 'taleggio', 'vacherin', 'milk chocolate', 'whey protein', 'casein protein', \n",
    "    'egg noodles', 'egg whites', 'egg yolks', 'hollandaise sauce', 'aioli', 'flan', \n",
    "    'quiche', 'meringue', 'pavlova', 'egg wash', 'frittata', 'omelette', 'scrambled eggs', \n",
    "    'poached eggs', 'hard-boiled eggs', 'deviled eggs', 'eggnog', 'brioche', 'challah', \n",
    "    'pound cake', 'sponge cake', 'angel food cake', 'ladyfingers', 'mousse', 'souffle', \n",
    "    'creme brulee', 'panna cotta', 'tiramisu', 'yorkshire pudding', 'beef broth', \n",
    "    'chicken broth', 'fish sauce', 'oyster sauce', 'worcestershire sauce', 'caesar dressing', \n",
    "    'carbonara sauce', 'béarnaise sauce', 'gravlax', 'smoked salmon', 'caviar', 'anchovy paste', \n",
    "    'fish stock'\n",
    "]))\n",
    "\n",
    "\n",
    "# Function to check if a RecipeIngredientParts is vegetarian\n",
    "def is_vegetarian(ingredient):\n",
    "    for keyword in non_vegetarian_keywords:\n",
    "        if keyword in ingredient.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Function to check if a RecipeIngredientParts is vegan\n",
    "def is_vegan(ingredient):\n",
    "    for keyword in non_vegan_keywords:\n",
    "        if keyword in ingredient.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Apply the is_vegetarian function to the RecipeIngredientParts column\n",
    "df_recipes['is_vegetarian'] = df_recipes['RecipeIngredientParts'].apply(is_vegetarian)\n",
    "\n",
    "# Apply the is_vegan function to the RecipeIngredientParts column\n",
    "df_recipes['is_vegan'] = df_recipes['RecipeIngredientParts'].apply(is_vegan)\n",
    "\n",
    "# Map the diet category based on the is_vegetarian and is_vegan columns\n",
    "df_recipes['diet_category'] = df_recipes.apply(lambda row: 'Vegetarian' if row['is_vegetarian'] else 'Vegan' if row['is_vegan'] else 'Omnivore', axis=1)\n",
    "\n",
    "# create TotalTime_Recipe column\n",
    "df_recipes['TotalTime_Recipe'] = df_recipes['CookTime'] + df_recipes['PrepTime']\n",
    "\n",
    "# drop columns\n",
    "df_recipes = df_recipes.drop(columns=['Name', 'CookTime', 'PrepTime', 'RecipeIngredientParts', 'RecipeIngredientQuantities', 'RecipeYield', 'is_vegetarian', 'is_vegan'])\n",
    "# dtype conversion\n",
    "df_recipes[\"RecipeCategory\"] = df_recipes[\"RecipeCategory\"].astype(\"category\")\n",
    "df_recipes[\"diet_category\"] = df_recipes[\"diet_category\"].astype(\"category\")\n",
    "# rename columns\n",
    "df_recipes = df_recipes.rename(columns={\"diet_category\": \"recipe_diet_category\"})\n",
    "\n",
    "df_recipes.info()\n",
    "df_recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorId    0\n",
      "Diet        1\n",
      "Age         0\n",
      "dtype: int64\n",
      "['Vegetarian' 'Vegan' 'Omnivore' nan]\n",
      "AuthorId    0\n",
      "Diet        0\n",
      "Age         0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271907 entries, 0 to 271906\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count   Dtype   \n",
      "---  ------              --------------   -----   \n",
      " 0   AuthorId            271907 non-null  object  \n",
      " 1   user_diet_category  271907 non-null  category\n",
      " 2   Age                 271907 non-null  int64   \n",
      "dtypes: category(1), int64(1), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>user_diet_category</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000120E</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000014D</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000015A</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000016E</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000027E</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AuthorId user_diet_category  Age\n",
       "0  10000120E         Vegetarian   46\n",
       "1   1000014D              Vegan   18\n",
       "2   1000015A         Vegetarian   58\n",
       "3   1000016E         Vegetarian   32\n",
       "4   1000027E              Vegan   61"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diet = pd.read_csv('data/diet.csv')\n",
    "\n",
    "# chcek for missing values in the data\n",
    "print(df_diet.isnull().sum())\n",
    "\n",
    "# replace missing value in Diet with \"Omnivore\"\n",
    "print(df_diet[\"Diet\"].unique())\n",
    "df_diet[\"Diet\"] = df_diet[\"Diet\"].fillna(\"Omnivore\")\n",
    "\n",
    "# check again\n",
    "print(df_diet.isnull().sum())\n",
    "\n",
    "# Change data type of Diet to category\n",
    "df_diet[\"Diet\"] = df_diet[\"Diet\"].astype(\"category\")\n",
    "\n",
    "# rename the column Diet to diet_category\n",
    "df_diet = df_diet.rename(columns={\"Diet\": \"user_diet_category\"})\n",
    "\n",
    "df_diet.info()\n",
    "df_diet.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorId        0\n",
      "RecipeId        0\n",
      "Time            0\n",
      "HighCalories    0\n",
      "HighProtein     0\n",
      "LowFat          0\n",
      "LowSugar        0\n",
      "HighFiber       0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   AuthorId                140195 non-null  object \n",
      " 1   RecipeId                140195 non-null  int64  \n",
      " 2   TotalTime_Requested     140195 non-null  float64\n",
      " 3   HighCalories_Requested  140195 non-null  boolean\n",
      " 4   HighProtein_Requested   140195 non-null  boolean\n",
      " 5   LowFat_Requested        140195 non-null  boolean\n",
      " 6   LowSugar_Requested      140195 non-null  boolean\n",
      " 7   HighFiber_Requested     140195 non-null  boolean\n",
      "dtypes: boolean(5), float64(1), int64(1), object(1)\n",
      "memory usage: 4.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>TotalTime_Requested</th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>LowSugar_Requested</th>\n",
       "      <th>HighFiber_Requested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001012259B</td>\n",
       "      <td>73440</td>\n",
       "      <td>1799.950949</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437641B</td>\n",
       "      <td>365718</td>\n",
       "      <td>4201.820980</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1803340263D</td>\n",
       "      <td>141757</td>\n",
       "      <td>6299.861496</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854048B</td>\n",
       "      <td>280351</td>\n",
       "      <td>19801.365796</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2277685E</td>\n",
       "      <td>180505</td>\n",
       "      <td>5400.093457</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AuthorId  RecipeId  TotalTime_Requested  HighCalories_Requested   \n",
       "0  2001012259B     73440          1799.950949                   False  \\\n",
       "1      437641B    365718          4201.820980                   False   \n",
       "2  1803340263D    141757          6299.861496                   False   \n",
       "3      854048B    280351         19801.365796                   False   \n",
       "4     2277685E    180505          5400.093457                   False   \n",
       "\n",
       "   HighProtein_Requested  LowFat_Requested  LowSugar_Requested   \n",
       "0                  False             False                True  \\\n",
       "1                   True             False               False   \n",
       "2                  False              True               False   \n",
       "3                   True              True                True   \n",
       "4                  False             False                True   \n",
       "\n",
       "   HighFiber_Requested  \n",
       "0                False  \n",
       "1                 True  \n",
       "2                False  \n",
       "3                 True  \n",
       "4                False  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_requests = pd.read_csv('data/requests.csv')\n",
    "\n",
    "# check for missing values\n",
    "print(df_requests.isnull().sum())\n",
    "\n",
    "#dtype\n",
    "df_requests['HighCalories'] = df_requests['HighCalories'].astype('boolean')\n",
    "\n",
    "df_requests['HighProtein'] = df_requests['HighProtein'].replace({'Indifferent': False, 'Yes': True})\n",
    "df_requests['HighProtein'] = df_requests['HighProtein'].astype('boolean')\n",
    "\n",
    "df_requests['LowFat'] = df_requests['LowFat'].astype('boolean')\n",
    "\n",
    "df_requests['LowSugar'] = df_requests['LowSugar'].replace({'Indifferent': False, '0': True})\n",
    "df_requests['LowSugar'] = df_requests['LowSugar'].astype('boolean')\n",
    "\n",
    "df_requests['HighFiber'] = df_requests['HighFiber'].astype('boolean')\n",
    "\n",
    "# rename columns\n",
    "df_requests.rename(columns={'Time': 'TotalTime_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'HighCalories': 'HighCalories_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'HighProtein': 'HighProtein_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'LowFat': 'LowFat_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'LowSugar': 'LowSugar_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'HighFiber': 'HighFiber_Requested'}, inplace=True)\n",
    "\n",
    "df_requests.info() \n",
    "df_requests.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   AuthorId   140195 non-null  object \n",
      " 1   RecipeId   140195 non-null  int64  \n",
      " 2   Like       97381 non-null   boolean\n",
      " 3   TestSetId  42814 non-null   float64\n",
      "dtypes: boolean(1), float64(1), int64(1), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zq/34s415f93837022tv_1wj9kh0000gn/T/ipykernel_13842/4131158636.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_reviews = pd.read_csv('data/reviews.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Like</th>\n",
       "      <th>TestSetId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2492191A</td>\n",
       "      <td>33671</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002019979A</td>\n",
       "      <td>92647</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408594E</td>\n",
       "      <td>161770</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001625557E</td>\n",
       "      <td>108231</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001427116E</td>\n",
       "      <td>71109</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AuthorId  RecipeId  Like  TestSetId\n",
       "0     2492191A     33671  <NA>        1.0\n",
       "1  2002019979A     92647  <NA>        2.0\n",
       "2      408594E    161770  <NA>        3.0\n",
       "3  2001625557E    108231  <NA>        4.0\n",
       "4  2001427116E     71109  <NA>        5.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_csv('data/reviews.csv')\n",
    "\n",
    "#sns.countplot(data=df_reviews, x='Rating')  # Rating is only 2 except 2 rows -> drop Rating column\n",
    "df_reviews = df_reviews.drop('Rating', axis=1)\n",
    "\n",
    "# check for missing values\n",
    "# print(df_reviews.isnull().sum())\n",
    "\n",
    "# dtype \n",
    "df_reviews['Like'] = df_reviews['Like'].astype('boolean')\n",
    "\n",
    "df_reviews.info()\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aggregation (Merge the tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep all request, add info about custormers diet when exit -> df_diet right_join df_requests\n",
    "merged_df_diet_request = df_diet.merge(df_requests, on='AuthorId', how='right')\n",
    "#merged_df_diet_request.head(100)\n",
    "\n",
    "# request without matched recipe, or recipe without request is useless  -> normal join \n",
    "merged_df_diet_request_recipes = merged_df_diet_request.merge(df_recipes, on='RecipeId')\n",
    "#merged_df_diet_request_recipes.tail(100)\n",
    "\n",
    "# review without request,recipes is useless -> left \n",
    "merged_df_diet_request_recipes_reviews = merged_df_diet_request_recipes.merge(df_reviews, on=['RecipeId', 'AuthorId'], how='left')\n",
    "#merged_df_diet_request_recipes_reviews.info()\n",
    "\n",
    "merged_df = merged_df_diet_request_recipes_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Data Cleaning (after merged) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ishanjainoffical.medium.com/choosing-the-right-correlation-pearson-vs-spearman-vs-kendalls-tau-02dc7d7dd01d\n",
    "def plot_corr(df, title, is_like=True):\n",
    "    if 'Like' in df:\n",
    "        df = df[df['Like'] == 1]\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(25, 7))\n",
    "    nutrients_corr = df.corr(method='kendall') \n",
    "    mask = np.triu(np.ones_like(nutrients_corr, dtype=bool))\n",
    "    cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    sns.heatmap(nutrients_corr, mask=mask, cmap=cmap, annot=True, fmt=\".2f\", ax=ax1, center=0)\n",
    "    ax1.set_title(title + ' - kendall', fontsize=16)\n",
    "    nutrients_corr = df.corr(method='pearson')\n",
    "    mask = np.triu(np.ones_like(nutrients_corr, dtype=bool))\n",
    "    cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    sns.heatmap(nutrients_corr, mask=mask, cmap=cmap, annot=True, fmt=\".2f\", ax=ax2, center=0)\n",
    "    ax2.set_title(title + ' - pearson', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> Drop\n",
    "merged_df = merged_df.drop(columns=['AuthorId', 'RecipeId', 'TotalTime_Requested', 'TotalTime_Recipe', 'RecipeServings', 'RecipeCategory', 'SaturatedFatContent', 'CholesterolContent', 'FiberContent', 'SugarContent', 'LowSugar_Requested', 'HighFiber_Requested', 'Age'])\n",
    "# One-Hot_encoding\n",
    "merged_df = pd.get_dummies(merged_df, columns=['user_diet_category', 'recipe_diet_category'])\n",
    "\n",
    "# drop user_diet_category, recipe_diet_category\n",
    "# merged_df = merged_df.drop(columns=['user_diet_category', 'recipe_diet_category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column merged_df['same_category]: \n",
    "    # = 1 if recipe_category == Ominvore but user_diet_category == Vegetarian or Vegan\n",
    "    # = 1 if recipe_category == Vegetarian but user_diet_category == Vegan \n",
    "    # else 0 \n",
    "\n",
    "#merged_df['same_category'] = merged_df.apply(lambda row: 1 if (row['recipe_diet_category'] == 'Omnivore' and (row['user_diet_category'] == 'Vegetarian' or row['user_diet_category'] == 'Vegan')) \n",
    "#                    or ((row['recipe_diet_category'] == 'Vegetarian' or row['recipe_diet_category'] == 'Omnivore') and row['user_diet_category'] == 'Vegan') else 0, axis=1)\n",
    "\n",
    "# corr between Like and same_category\n",
    "#merged_df[['Like', 'same_category']].corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot corr for whole merged_df\n",
    "#plot_corr(merged_df.drop(columns=['user_diet_category', 'recipe_diet_category']), title=\"Full data without categorical columns\", is_like=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 16 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   HighCalories_Requested           140195 non-null  boolean\n",
      " 1   HighProtein_Requested            140195 non-null  boolean\n",
      " 2   LowFat_Requested                 140195 non-null  boolean\n",
      " 3   Calories                         140195 non-null  float64\n",
      " 4   FatContent                       140195 non-null  float64\n",
      " 5   SodiumContent                    140195 non-null  float64\n",
      " 6   CarbohydrateContent              140195 non-null  float64\n",
      " 7   ProteinContent                   140195 non-null  float64\n",
      " 8   Like                             97381 non-null   boolean\n",
      " 9   TestSetId                        42814 non-null   float64\n",
      " 10  user_diet_category_Omnivore      140195 non-null  bool   \n",
      " 11  user_diet_category_Vegan         140195 non-null  bool   \n",
      " 12  user_diet_category_Vegetarian    140195 non-null  bool   \n",
      " 13  recipe_diet_category_Omnivore    140195 non-null  bool   \n",
      " 14  recipe_diet_category_Vegan       140195 non-null  bool   \n",
      " 15  recipe_diet_category_Vegetarian  140195 non-null  bool   \n",
      "dtypes: bool(6), boolean(4), float64(6)\n",
      "memory usage: 8.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>Like</th>\n",
       "      <th>TestSetId</th>\n",
       "      <th>user_diet_category_Omnivore</th>\n",
       "      <th>user_diet_category_Vegan</th>\n",
       "      <th>user_diet_category_Vegetarian</th>\n",
       "      <th>recipe_diet_category_Omnivore</th>\n",
       "      <th>recipe_diet_category_Vegan</th>\n",
       "      <th>recipe_diet_category_Vegetarian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighCalories_Requested  HighProtein_Requested  LowFat_Requested  Calories   \n",
       "0                   False                  False             False     241.3  \\\n",
       "1                    True                   True              True     241.3   \n",
       "2                    True                  False             False     241.3   \n",
       "3                    True                   True              True     241.3   \n",
       "4                   False                   True              True     241.3   \n",
       "\n",
       "   FatContent  SodiumContent  CarbohydrateContent  ProteinContent   Like   \n",
       "0        10.1           13.1                 31.8             6.7  False  \\\n",
       "1        10.1           13.1                 31.8             6.7  False   \n",
       "2        10.1           13.1                 31.8             6.7  False   \n",
       "3        10.1           13.1                 31.8             6.7  False   \n",
       "4        10.1           13.1                 31.8             6.7  False   \n",
       "\n",
       "   TestSetId  user_diet_category_Omnivore  user_diet_category_Vegan   \n",
       "0        NaN                        False                     False  \\\n",
       "1        NaN                        False                     False   \n",
       "2        NaN                        False                     False   \n",
       "3        NaN                        False                      True   \n",
       "4        NaN                        False                      True   \n",
       "\n",
       "   user_diet_category_Vegetarian  recipe_diet_category_Omnivore   \n",
       "0                           True                          False  \\\n",
       "1                           True                          False   \n",
       "2                           True                          False   \n",
       "3                          False                          False   \n",
       "4                          False                          False   \n",
       "\n",
       "   recipe_diet_category_Vegan  recipe_diet_category_Vegetarian  \n",
       "0                       False                             True  \n",
       "1                       False                             True  \n",
       "2                       False                             True  \n",
       "3                       False                             True  \n",
       "4                       False                             True  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.info()\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Spliting : Test - Train - Val \n",
    "\n",
    "<span style=\"color:red\">\n",
    "\n",
    "- randomly split with shuffle=True  (Note: remember the random_state number to be able to reproduce the split) \n",
    "- k-cross validation? \n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87642 entries, 34459 to 102791\n",
      "Data columns (total 14 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   HighCalories_Requested           87642 non-null  boolean\n",
      " 1   HighProtein_Requested            87642 non-null  boolean\n",
      " 2   LowFat_Requested                 87642 non-null  boolean\n",
      " 3   Calories                         87642 non-null  float64\n",
      " 4   FatContent                       87642 non-null  float64\n",
      " 5   SodiumContent                    87642 non-null  float64\n",
      " 6   CarbohydrateContent              87642 non-null  float64\n",
      " 7   ProteinContent                   87642 non-null  float64\n",
      " 8   user_diet_category_Omnivore      87642 non-null  bool   \n",
      " 9   user_diet_category_Vegan         87642 non-null  bool   \n",
      " 10  user_diet_category_Vegetarian    87642 non-null  bool   \n",
      " 11  recipe_diet_category_Omnivore    87642 non-null  bool   \n",
      " 12  recipe_diet_category_Vegan       87642 non-null  bool   \n",
      " 13  recipe_diet_category_Vegetarian  87642 non-null  bool   \n",
      "dtypes: bool(6), boolean(3), float64(5)\n",
      "memory usage: 5.0 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TrainVal vs. Test split\n",
    "test_dataframe = merged_df[merged_df['TestSetId'].notna()]\n",
    "#test_dataframe.head(100)\n",
    "\n",
    "# Train vs. Val split\n",
    "train_val_dataframe = merged_df[merged_df['TestSetId'].isna()]\n",
    "\n",
    "# Prepare train val for training \n",
    "train_val_dataframe = merged_df[merged_df['Like'].notna()]\n",
    "train_val_dataframe = train_val_dataframe.drop('TestSetId', axis=1)\n",
    "# put Target (Like column) at the end \n",
    "like_column = train_val_dataframe.pop('Like')\n",
    "train_val_dataframe['Like'] = like_column\n",
    "train_val_dataframe['Like'] = train_val_dataframe['Like'].astype(int)\n",
    "#train_val_dataframe.head(100)\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "  train_test_split(train_val_dataframe.iloc[:, :-1], train_val_dataframe.iloc[:, -1:],\n",
    "                   test_size=0.1, \n",
    "                   shuffle=True,\n",
    "                   random_state=3)\n",
    "\n",
    "X_train.info()\n",
    "#X_val.head()\n",
    "#y_train.info()\n",
    "#y_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Änderung: \n",
    "Bei meta_parameter_grid wurde hinzugefügt:\n",
    "- parameter_grid_gaussianNB\n",
    "- parameter_grid_linearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter pca for estimator Pipeline(steps=[('scaler', StandardScaler()), ('model', None)]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 668, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 188, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py\", line 54, in _set_params\n    super().set_params(**params)\n  File \"/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\", line 245, in set_params\n    raise ValueError(\nValueError: Invalid parameter pca for estimator Pipeline(steps=[('scaler', StandardScaler()), ('model', None)]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 95\u001b[0m\n\u001b[1;32m     84\u001b[0m search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     85\u001b[0m     pipeline,\n\u001b[1;32m     86\u001b[0m     meta_parameter_grid, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Training and grid search\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Replace X_train and y_train with your actual data\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Uncomment below to print the best parameters\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, search\u001b[38;5;241m.\u001b[39mbest_params_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(CV score=\u001b[39m\u001b[38;5;132;01m%0.3f\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter pca for estimator Pipeline(steps=[('scaler', StandardScaler()), ('model', None)]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Model initialization\n",
    "model_logistic_regression = LogisticRegression(max_iter=100)\n",
    "model_random_forest = RandomForestClassifier()\n",
    "model_gradient_boosting = GradientBoostingClassifier()\n",
    "model_gaussianNB = GaussianNB()\n",
    "model_linearSVC = LinearSVC(max_iter=10000)\n",
    "\n",
    "# Data scaling\n",
    "transform_scaler = StandardScaler()\n",
    "\n",
    "# Dimensionality reduction (optional, based on PCA analysis)\n",
    "# transform_pca = PCA()\n",
    "\n",
    "# Pipeline setup\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", transform_scaler),\n",
    "    # Uncomment the following line if PCA is necessary\n",
    "    # (\"pca\", transform_pca),\n",
    "    (\"model\", None)\n",
    "])\n",
    "\n",
    "# Hyperparameters for grid search\n",
    "parameter_grid_preprocessing = {\n",
    "    # \"pca__n_components\": [7, 8],  # Uncomment if using PCA\n",
    "}\n",
    "\n",
    "parameter_grid_gaussianNB = {\n",
    "    \"model\": [model_gaussianNB],\n",
    "    \"model__var_smoothing\": [1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "\n",
    "# parameter_grid_linearSVC = {\n",
    "#     \"model\": [model_linearSVC],\n",
    "#     \"model__C\": [0.1, 1, 10]  # Regularization parameter\n",
    "# }\n",
    "parameter_grid_SVC = {\n",
    "    \"model\": [SVC()],\n",
    "    \"model__C\": [0.1, 1, 10],  # Regularization parameter\n",
    "    \"model__kernel\": ['linear', 'rbf'],  # Kernel type\n",
    "    \"model__gamma\": [0.1, 1, 10]  # Kernel coefficient for 'rbf'\n",
    "}\n",
    "\n",
    "parameter_grid_logistic_regression = {\n",
    "    \"model\": [model_logistic_regression],\n",
    "    \"model__C\": [0.1, 1, 10]  # Inverse regularization strength\n",
    "}\n",
    "\n",
    "parameter_grid_gradient_boosting = {\n",
    "    \"model\": [model_gradient_boosting],\n",
    "    \"model__n_estimators\": [10, 20, 30]\n",
    "}\n",
    "\n",
    "# Updated parameter grid for RandomForestClassifier\n",
    "parameter_grid_random_forest = {\n",
    "    # \"pca__n_components\": [None],  # Reduced number of PCA components\n",
    "    \"model__n_estimators\": [100, 200],  # Reduced number of trees\n",
    "    \"model__max_depth\": [10, 20, None],  # Simplified max_depth\n",
    "}\n",
    "\n",
    "# Combining all parameter grids\n",
    "meta_parameter_grid = [\n",
    "    parameter_grid_logistic_regression,\n",
    "    parameter_grid_random_forest,\n",
    "    parameter_grid_gradient_boosting,\n",
    "    parameter_grid_gaussianNB,\n",
    "    parameter_grid_SVC\n",
    "]\n",
    "\n",
    "# Adding preprocessing parameters to each model's grid\n",
    "meta_parameter_grid = [{**parameter_grid_preprocessing, **model_grid}\n",
    "                       for model_grid in meta_parameter_grid]\n",
    "\n",
    "# GridSearchCV setup\n",
    "search = GridSearchCV(\n",
    "    pipeline,\n",
    "    meta_parameter_grid, \n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=2, \n",
    "    cv=5,  # Number of folds for cross-validation\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# Training and grid search\n",
    "# Replace X_train and y_train with your actual data\n",
    "search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Uncomment below to print the best parameters\n",
    "print(\"Best parameters:\", search.best_params_, \"(CV score=%0.3f)\" % search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'model__max_depth': None, 'model__n_estimators': 100, 'pca__n_components': None} (CV score=0.589)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.decomposition import PCA\n",
    "# # Model initialization\n",
    "# model_random_forest = RandomForestClassifier()\n",
    "\n",
    "# # Data scaling\n",
    "# transform_scaler = StandardScaler()\n",
    "\n",
    "# # Dimensionality reduction (PCA)\n",
    "# transform_pca = PCA()\n",
    "\n",
    "# # Pipeline setup\n",
    "# pipeline = Pipeline([\n",
    "#     (\"scaler\", transform_scaler),\n",
    "#     (\"pca\", transform_pca),\n",
    "#     (\"model\", model_random_forest)\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "# parameter_grid_random_forest = {\n",
    "#     \"pca__n_components\": [None],  # Reduced number of PCA components\n",
    "#     \"model__n_estimators\": [100, 200],  # Reduced number of trees\n",
    "#     \"model__max_depth\": [10, 20, None],  # Simplified max_depth\n",
    "# }\n",
    "\n",
    "\n",
    "# # GridSearchCV setup\n",
    "# search = GridSearchCV(\n",
    "#     pipeline,\n",
    "#     parameter_grid_random_forest, \n",
    "#     scoring=\"balanced_accuracy\",\n",
    "#     n_jobs=-1,  # Use all available cores\n",
    "#     cv=5  # Number of folds for cross-validation\n",
    "# )\n",
    "\n",
    "# # Uncomment below to train the model using GridSearchCV\n",
    "# # Replace X_train and y_train with your actual training data\n",
    "# search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# # Uncomment below to print the best parameters\n",
    "# print(\"Best parameters:\", search.best_params_, \"(CV score=%0.3f)\" % search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.6042375885354317\n",
      "true     0    1\n",
      "pred           \n",
      "0     8161  978\n",
      "1      287  313\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of model on test set\n",
    "print(\"Score on test set:\", search.score(X_val, y_val.values.ravel()))\n",
    "\n",
    "# prediction and show contingency table\n",
    "ct = pd.crosstab(search.best_estimator_.predict(X_val), y_val.values.ravel(),\n",
    "                 rownames=[\"pred\"], colnames=[\"true\"])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 10, 'model__n_estimators': 100, 'pca__n_components': None} 0.5353861240411725\n",
      "{'model__max_depth': 10, 'model__n_estimators': 200, 'pca__n_components': None} 0.5366278427565268\n",
      "{'model__max_depth': 20, 'model__n_estimators': 100, 'pca__n_components': None} 0.5841439069093239\n",
      "{'model__max_depth': 20, 'model__n_estimators': 200, 'pca__n_components': None} 0.5834303689585878\n",
      "{'model__max_depth': None, 'model__n_estimators': 100, 'pca__n_components': None} 0.5885887395002033\n",
      "{'model__max_depth': None, 'model__n_estimators': 200, 'pca__n_components': None} 0.5870110344808849\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# (optional, if you're curious) for a detailed look on the performance of the different models\n",
    "def get_search_score_overview():\n",
    "  for c,s in zip(search.cv_results_[\"params\"],search.cv_results_[\"mean_test_score\"]):\n",
    "      print(c, s)\n",
    "\n",
    "print(get_search_score_overview())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>user_diet_category_Omnivore</th>\n",
       "      <th>user_diet_category_Vegan</th>\n",
       "      <th>user_diet_category_Vegetarian</th>\n",
       "      <th>recipe_diet_category_Omnivore</th>\n",
       "      <th>recipe_diet_category_Vegan</th>\n",
       "      <th>recipe_diet_category_Vegetarian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HighCalories_Requested  HighProtein_Requested  LowFat_Requested  Calories   \n",
       "5                    False                   True             False     241.3  \\\n",
       "7                    False                  False             False     241.3   \n",
       "8                    False                  False             False     241.3   \n",
       "14                   False                   True             False     241.3   \n",
       "15                   False                   True             False     241.3   \n",
       "\n",
       "    FatContent  SodiumContent  CarbohydrateContent  ProteinContent   \n",
       "5         10.1           13.1                 31.8             6.7  \\\n",
       "7         10.1           13.1                 31.8             6.7   \n",
       "8         10.1           13.1                 31.8             6.7   \n",
       "14        10.1           13.1                 31.8             6.7   \n",
       "15        10.1           13.1                 31.8             6.7   \n",
       "\n",
       "    user_diet_category_Omnivore  user_diet_category_Vegan   \n",
       "5                         False                      True  \\\n",
       "7                         False                     False   \n",
       "8                         False                     False   \n",
       "14                        False                      True   \n",
       "15                         True                     False   \n",
       "\n",
       "    user_diet_category_Vegetarian  recipe_diet_category_Omnivore   \n",
       "5                           False                          False  \\\n",
       "7                            True                          False   \n",
       "8                            True                          False   \n",
       "14                          False                          False   \n",
       "15                          False                          False   \n",
       "\n",
       "    recipe_diet_category_Vegan  recipe_diet_category_Vegetarian  \n",
       "5                        False                             True  \n",
       "7                        False                             True  \n",
       "8                        False                             True  \n",
       "14                       False                             True  \n",
       "15                       False                             True  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare test data for prediction\n",
    "test_set_id = test_dataframe.pop('TestSetId')\n",
    "test_dataframe = test_dataframe.drop('Like', axis=1)\n",
    "test_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "model = search.best_estimator_ \n",
    "test_dataframe[\"Like\"] = model.predict(test_dataframe)\n",
    "\n",
    "#TODO: \n",
    "\n",
    "# prediction := List if Like \n",
    "# test_set_id := List of test ID\n",
    "\n",
    "# write to CSV file in the same order  (den Code unten anpassenm)\n",
    "# 1.ID  1.Like \n",
    "# 2.ID  2.Like\n",
    "\n",
    "output = pd.DataFrame(test_dataframe[\"Like\"])\n",
    "output[\"id\"] = test_set_id.astype(\"int\")\n",
    "\n",
    "output = output.rename(columns={'Like': 'prediction'})\n",
    "output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "\n",
    "output.to_csv('recipe_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "0    40297\n",
       "1     2517\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out many 0 and 1 in output\n",
    "output[\"prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume that our id column is the index of the dataframe\n",
    "\n",
    "# print(test_dataframe)\n",
    "#output = pd.DataFrame(test_dataframe[\"Like\"])\n",
    "# output = output.reset_index(drop=True)\n",
    "#output[\"id\"] = output.index + 1\n",
    "#output = output.rename(columns={'Like': 'prediction'})\n",
    "#output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "# output length\n",
    "#print(len(output))\n",
    "#output.to_csv('recipe_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
