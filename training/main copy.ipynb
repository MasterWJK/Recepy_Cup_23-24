{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "#import sweetviz as sv\n",
    "#import shap\n",
    "#from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "seed = 2024  #seed = 2024: train model as stated in example_crisp_dm_pipeline.ipynb\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Data Cleaning: Readin data and preprocessing individual table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75604 entries, 0 to 75603\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   RecipeId              75604 non-null  int64   \n",
      " 1   RecipeCategory        75604 non-null  category\n",
      " 2   Calories              75604 non-null  float64 \n",
      " 3   FatContent            75604 non-null  float64 \n",
      " 4   SaturatedFatContent   75604 non-null  float64 \n",
      " 5   CholesterolContent    75604 non-null  float64 \n",
      " 6   SodiumContent         75604 non-null  float64 \n",
      " 7   CarbohydrateContent   75604 non-null  float64 \n",
      " 8   FiberContent          75604 non-null  float64 \n",
      " 9   SugarContent          75604 non-null  float64 \n",
      " 10  ProteinContent        75604 non-null  float64 \n",
      " 11  RecipeServings        48891 non-null  float64 \n",
      " 12  recipe_diet_category  75604 non-null  category\n",
      " 13  TotalTime_Recipe      75604 non-null  int64   \n",
      "dtypes: category(2), float64(10), int64(2)\n",
      "memory usage: 7.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>RecipeCategory</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SaturatedFatContent</th>\n",
       "      <th>CholesterolContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>FiberContent</th>\n",
       "      <th>SugarContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>RecipeServings</th>\n",
       "      <th>recipe_diet_category</th>\n",
       "      <th>TotalTime_Recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73440</td>\n",
       "      <td>Other</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365718</td>\n",
       "      <td>Other</td>\n",
       "      <td>370.8</td>\n",
       "      <td>17.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>553.3</td>\n",
       "      <td>44.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141757</td>\n",
       "      <td>Other</td>\n",
       "      <td>377.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>45.7</td>\n",
       "      <td>1501.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280351</td>\n",
       "      <td>Other</td>\n",
       "      <td>282.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>50.5</td>\n",
       "      <td>630.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>19800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180505</td>\n",
       "      <td>Other</td>\n",
       "      <td>257.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>110.7</td>\n",
       "      <td>160.9</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>5400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecipeId RecipeCategory  Calories  FatContent  SaturatedFatContent   \n",
       "0     73440          Other     241.3        10.1                  1.2  \\\n",
       "1    365718          Other     370.8        17.5                  7.2   \n",
       "2    141757          Other     377.6        20.9                 10.5   \n",
       "3    280351          Other     282.8        16.5                 10.3   \n",
       "4    180505          Other     257.5         8.6                  2.4   \n",
       "\n",
       "   CholesterolContent  SodiumContent  CarbohydrateContent  FiberContent   \n",
       "0                 0.0           13.1                 31.8           2.3  \\\n",
       "1                22.9          553.3                 44.3           1.6   \n",
       "2                45.7         1501.8                 36.6           3.8   \n",
       "3                50.5          630.2                 22.8           2.3   \n",
       "4               110.7          160.9                 39.8           0.4   \n",
       "\n",
       "   SugarContent  ProteinContent  RecipeServings recipe_diet_category   \n",
       "0           1.4             6.7             9.0           Vegetarian  \\\n",
       "1           2.2             9.4             8.0             Omnivore   \n",
       "2           6.1            12.9             8.0           Vegetarian   \n",
       "3           2.7            11.7             6.0             Omnivore   \n",
       "4          30.2             6.3             6.0                Vegan   \n",
       "\n",
       "   TotalTime_Recipe  \n",
       "0              1800  \n",
       "1              4200  \n",
       "2              6300  \n",
       "3             19800  \n",
       "4              5400  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipes = pd.read_csv('data/recipes.csv')\n",
    "\n",
    "# Consolidated Non-Vegetarian Keywords\n",
    "non_vegetarian_keywords = list(set([\n",
    "    'flounder', 'lobsters', 'lump', 'rack', 'shank', 'steak', 'scallops', 'alligator', \n",
    "    'livers', 'roe', 'ham', 'turkey', 'chicken', 'duck', 'bacon', 'tuna', 'swordfish', \n",
    "    'lobster', 'meatballs', 'salmon', 'sweetbreads', 'breasts', 'chicken-flavored', \n",
    "    'ducklings', 'drumstick', 'liver', 'shanks', 'rabbit', 'poultry', 'herring', \n",
    "    'mussels', 'clams', 'squid', 'pork', 'veal', 'haddock', 'chorizo', 'chihuahua', \n",
    "    'eel', 'stuffing', 'cod', 'gelatin', 'sausage', 'curd', 'thighs', 'lox', 'cabbage', \n",
    "    'wonton', 'bone', 'giblets', 'pheasant', 'quail', 'shrimp', 'fish', 'sole', \n",
    "    'gizzard', 'Canadian', 'pesto', 'truffles', 'anchovies', 'venison', 'pheasants', \n",
    "    'tenderloin', 'meats', 'tripe', 'breast', 'wings', 'ribs', 'sausages', 'trout', \n",
    "    'oysters', 'octopus', 'crab', 'prawns', 'catfish', 'sardines', 'mahi', 'halibut', \n",
    "    'bass', 'perch', 'tilapia', 'grouper'\n",
    "]))\n",
    "\n",
    "# Consolidated Non-Vegan Keywords\n",
    "non_vegan_keywords = list(set([\n",
    "    'milk', 'cheese', 'butter', 'egg', 'honey', 'mozzarella-cheddar', 'cream', 'whip', \n",
    "    'jarlsberg', 'fontina', 'ham', 'cheesecake', 'hollandaise', 'caviar', 'creamRegular', \n",
    "    'custard', 'yogurt', 'gouda', 'margarine', 'beef', 'salmon', 'sour', 'bisquick', \n",
    "    'carton', 'cotija', 'creme', 'buttercream', 'buttermilk', 'ricotta', 'cottage', \n",
    "    'eggs', 'mayonnaise', 'eggshells', 'lactose-free', 'skim', 'ghee', 'mascarpone', \n",
    "    'alfredo', 'whey', 'casein', 'lactose', 'albumin', 'bechamel', 'sour cream', \n",
    "    'cream cheese', 'feta', 'gorgonzola', 'parmesan', 'mozzarella', 'cheddar', 'brie', \n",
    "    'camembert', 'roquefort', 'stilton', 'blue cheese', 'colby', 'monterey jack', \n",
    "    'swiss cheese', 'provolone', 'edam', 'havarti', 'pecorino', 'asiago', 'emmental', \n",
    "    'gruyere', 'halloumi', 'manchego', 'paneer', 'queso fresco', 'ricotta salata', \n",
    "    'romano', 'taleggio', 'vacherin', 'milk chocolate', 'whey protein', 'casein protein', \n",
    "    'egg noodles', 'egg whites', 'egg yolks', 'hollandaise sauce', 'aioli', 'flan', \n",
    "    'quiche', 'meringue', 'pavlova', 'egg wash', 'frittata', 'omelette', 'scrambled eggs', \n",
    "    'poached eggs', 'hard-boiled eggs', 'deviled eggs', 'eggnog', 'brioche', 'challah', \n",
    "    'pound cake', 'sponge cake', 'angel food cake', 'ladyfingers', 'mousse', 'souffle', \n",
    "    'creme brulee', 'panna cotta', 'tiramisu', 'yorkshire pudding', 'beef broth', \n",
    "    'chicken broth', 'fish sauce', 'oyster sauce', 'worcestershire sauce', 'caesar dressing', \n",
    "    'carbonara sauce', 'béarnaise sauce', 'gravlax', 'smoked salmon', 'caviar', 'anchovy paste', \n",
    "    'fish stock'\n",
    "]))\n",
    "\n",
    "\n",
    "# Function to check if a RecipeIngredientParts is vegetarian\n",
    "def is_vegetarian(ingredient):\n",
    "    for keyword in non_vegetarian_keywords:\n",
    "        if keyword in ingredient.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Function to check if a RecipeIngredientParts is vegan\n",
    "def is_vegan(ingredient):\n",
    "    for keyword in non_vegan_keywords:\n",
    "        if keyword in ingredient.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Apply the is_vegetarian function to the RecipeIngredientParts column\n",
    "df_recipes['is_vegetarian'] = df_recipes['RecipeIngredientParts'].apply(is_vegetarian)\n",
    "\n",
    "# Apply the is_vegan function to the RecipeIngredientParts column\n",
    "df_recipes['is_vegan'] = df_recipes['RecipeIngredientParts'].apply(is_vegan)\n",
    "\n",
    "# Map the diet category based on the is_vegetarian and is_vegan columns\n",
    "df_recipes['diet_category'] = df_recipes.apply(lambda row: 'Vegetarian' if row['is_vegetarian'] else 'Vegan' if row['is_vegan'] else 'Omnivore', axis=1)\n",
    "\n",
    "# create TotalTime_Recipe column\n",
    "df_recipes['TotalTime_Recipe'] = df_recipes['CookTime'] + df_recipes['PrepTime']\n",
    "\n",
    "# drop columns\n",
    "df_recipes = df_recipes.drop(columns=['Name', 'CookTime', 'PrepTime', 'RecipeIngredientParts', 'RecipeIngredientQuantities', 'RecipeYield', 'is_vegetarian', 'is_vegan'])\n",
    "# dtype conversion\n",
    "df_recipes[\"RecipeCategory\"] = df_recipes[\"RecipeCategory\"].astype(\"category\")\n",
    "df_recipes[\"diet_category\"] = df_recipes[\"diet_category\"].astype(\"category\")\n",
    "# rename columns\n",
    "df_recipes = df_recipes.rename(columns={\"diet_category\": \"recipe_diet_category\"})\n",
    "\n",
    "df_recipes.info()\n",
    "df_recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorId    0\n",
      "Diet        1\n",
      "Age         0\n",
      "dtype: int64\n",
      "['Vegetarian' 'Vegan' 'Omnivore' nan]\n",
      "AuthorId    0\n",
      "Diet        0\n",
      "Age         0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271907 entries, 0 to 271906\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count   Dtype   \n",
      "---  ------              --------------   -----   \n",
      " 0   AuthorId            271907 non-null  object  \n",
      " 1   user_diet_category  271907 non-null  category\n",
      " 2   Age                 271907 non-null  int64   \n",
      "dtypes: category(1), int64(1), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>user_diet_category</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000120E</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000014D</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000015A</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000016E</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000027E</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AuthorId user_diet_category  Age\n",
       "0  10000120E         Vegetarian   46\n",
       "1   1000014D              Vegan   18\n",
       "2   1000015A         Vegetarian   58\n",
       "3   1000016E         Vegetarian   32\n",
       "4   1000027E              Vegan   61"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diet = pd.read_csv('data/diet.csv')\n",
    "\n",
    "# chcek for missing values in the data\n",
    "print(df_diet.isnull().sum())\n",
    "\n",
    "# replace missing value in Diet with \"Omnivore\"\n",
    "print(df_diet[\"Diet\"].unique())\n",
    "df_diet[\"Diet\"] = df_diet[\"Diet\"].fillna(\"Omnivore\")\n",
    "\n",
    "# check again\n",
    "print(df_diet.isnull().sum())\n",
    "\n",
    "# Change data type of Diet to category\n",
    "df_diet[\"Diet\"] = df_diet[\"Diet\"].astype(\"category\")\n",
    "\n",
    "# rename the column Diet to diet_category\n",
    "df_diet = df_diet.rename(columns={\"Diet\": \"user_diet_category\"})\n",
    "\n",
    "df_diet.info()\n",
    "df_diet.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorId        0\n",
      "RecipeId        0\n",
      "Time            0\n",
      "HighCalories    0\n",
      "HighProtein     0\n",
      "LowFat          0\n",
      "LowSugar        0\n",
      "HighFiber       0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   AuthorId                140195 non-null  object \n",
      " 1   RecipeId                140195 non-null  int64  \n",
      " 2   TotalTime_Requested     140195 non-null  float64\n",
      " 3   HighCalories_Requested  140195 non-null  boolean\n",
      " 4   HighProtein_Requested   140195 non-null  boolean\n",
      " 5   LowFat_Requested        140195 non-null  boolean\n",
      " 6   LowSugar_Requested      140195 non-null  boolean\n",
      " 7   HighFiber_Requested     140195 non-null  boolean\n",
      "dtypes: boolean(5), float64(1), int64(1), object(1)\n",
      "memory usage: 4.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>TotalTime_Requested</th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>LowSugar_Requested</th>\n",
       "      <th>HighFiber_Requested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001012259B</td>\n",
       "      <td>73440</td>\n",
       "      <td>1799.950949</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437641B</td>\n",
       "      <td>365718</td>\n",
       "      <td>4201.820980</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1803340263D</td>\n",
       "      <td>141757</td>\n",
       "      <td>6299.861496</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854048B</td>\n",
       "      <td>280351</td>\n",
       "      <td>19801.365796</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2277685E</td>\n",
       "      <td>180505</td>\n",
       "      <td>5400.093457</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AuthorId  RecipeId  TotalTime_Requested  HighCalories_Requested   \n",
       "0  2001012259B     73440          1799.950949                   False  \\\n",
       "1      437641B    365718          4201.820980                   False   \n",
       "2  1803340263D    141757          6299.861496                   False   \n",
       "3      854048B    280351         19801.365796                   False   \n",
       "4     2277685E    180505          5400.093457                   False   \n",
       "\n",
       "   HighProtein_Requested  LowFat_Requested  LowSugar_Requested   \n",
       "0                  False             False                True  \\\n",
       "1                   True             False               False   \n",
       "2                  False              True               False   \n",
       "3                   True              True                True   \n",
       "4                  False             False                True   \n",
       "\n",
       "   HighFiber_Requested  \n",
       "0                False  \n",
       "1                 True  \n",
       "2                False  \n",
       "3                 True  \n",
       "4                False  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_requests = pd.read_csv('data/requests.csv')\n",
    "\n",
    "# check for missing values\n",
    "print(df_requests.isnull().sum())\n",
    "\n",
    "#dtype\n",
    "df_requests['HighCalories'] = df_requests['HighCalories'].astype('boolean')\n",
    "\n",
    "df_requests['HighProtein'] = df_requests['HighProtein'].replace({'Indifferent': False, 'Yes': True})\n",
    "df_requests['HighProtein'] = df_requests['HighProtein'].astype('boolean')\n",
    "\n",
    "df_requests['LowFat'] = df_requests['LowFat'].astype('boolean')\n",
    "\n",
    "df_requests['LowSugar'] = df_requests['LowSugar'].replace({'Indifferent': False, '0': True})\n",
    "df_requests['LowSugar'] = df_requests['LowSugar'].astype('boolean')\n",
    "\n",
    "df_requests['HighFiber'] = df_requests['HighFiber'].astype('boolean')\n",
    "\n",
    "# rename columns\n",
    "df_requests.rename(columns={'Time': 'TotalTime_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'HighCalories': 'HighCalories_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'HighProtein': 'HighProtein_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'LowFat': 'LowFat_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'LowSugar': 'LowSugar_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'HighFiber': 'HighFiber_Requested'}, inplace=True)\n",
    "\n",
    "df_requests.info() \n",
    "df_requests.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   AuthorId   140195 non-null  object \n",
      " 1   RecipeId   140195 non-null  int64  \n",
      " 2   Like       97381 non-null   boolean\n",
      " 3   TestSetId  42814 non-null   float64\n",
      "dtypes: boolean(1), float64(1), int64(1), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zq/34s415f93837022tv_1wj9kh0000gn/T/ipykernel_12322/4131158636.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_reviews = pd.read_csv('data/reviews.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Like</th>\n",
       "      <th>TestSetId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2492191A</td>\n",
       "      <td>33671</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002019979A</td>\n",
       "      <td>92647</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408594E</td>\n",
       "      <td>161770</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001625557E</td>\n",
       "      <td>108231</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001427116E</td>\n",
       "      <td>71109</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AuthorId  RecipeId  Like  TestSetId\n",
       "0     2492191A     33671  <NA>        1.0\n",
       "1  2002019979A     92647  <NA>        2.0\n",
       "2      408594E    161770  <NA>        3.0\n",
       "3  2001625557E    108231  <NA>        4.0\n",
       "4  2001427116E     71109  <NA>        5.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_csv('data/reviews.csv')\n",
    "\n",
    "#sns.countplot(data=df_reviews, x='Rating')  # Rating is only 2 except 2 rows -> drop Rating column\n",
    "df_reviews = df_reviews.drop('Rating', axis=1)\n",
    "\n",
    "# check for missing values\n",
    "# print(df_reviews.isnull().sum())\n",
    "\n",
    "# dtype \n",
    "df_reviews['Like'] = df_reviews['Like'].astype('boolean')\n",
    "\n",
    "df_reviews.info()\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aggregation (Merge the tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep all request, add info about custormers diet when exit -> df_diet right_join df_requests\n",
    "merged_df_diet_request = df_diet.merge(df_requests, on='AuthorId', how='right')\n",
    "#merged_df_diet_request.head(100)\n",
    "\n",
    "# request without matched recipe, or recipe without request is useless  -> normal join \n",
    "merged_df_diet_request_recipes = merged_df_diet_request.merge(df_recipes, on='RecipeId')\n",
    "#merged_df_diet_request_recipes.tail(100)\n",
    "\n",
    "# review without request,recipes is useless -> left \n",
    "merged_df_diet_request_recipes_reviews = merged_df_diet_request_recipes.merge(df_reviews, on=['RecipeId', 'AuthorId'], how='left')\n",
    "#merged_df_diet_request_recipes_reviews.info()\n",
    "\n",
    "merged_df = merged_df_diet_request_recipes_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Data Cleaning (after merged) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ishanjainoffical.medium.com/choosing-the-right-correlation-pearson-vs-spearman-vs-kendalls-tau-02dc7d7dd01d\n",
    "def plot_corr(df, title, is_like=True):\n",
    "    if 'Like' in df:\n",
    "        df = df[df['Like'] == 1]\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(25, 7))\n",
    "    nutrients_corr = df.corr(method='kendall') \n",
    "    mask = np.triu(np.ones_like(nutrients_corr, dtype=bool))\n",
    "    cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    sns.heatmap(nutrients_corr, mask=mask, cmap=cmap, annot=True, fmt=\".2f\", ax=ax1, center=0)\n",
    "    ax1.set_title(title + ' - kendall', fontsize=16)\n",
    "    nutrients_corr = df.corr(method='pearson')\n",
    "    mask = np.triu(np.ones_like(nutrients_corr, dtype=bool))\n",
    "    cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    sns.heatmap(nutrients_corr, mask=mask, cmap=cmap, annot=True, fmt=\".2f\", ax=ax2, center=0)\n",
    "    ax2.set_title(title + ' - pearson', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>Like</th>\n",
       "      <th>TestSetId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140190</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>121.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1175.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140191</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>652.2</td>\n",
       "      <td>25.8</td>\n",
       "      <td>435.5</td>\n",
       "      <td>51.9</td>\n",
       "      <td>50.1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7148.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140192</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>223.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>725.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>26.7</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140193</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2229.8</td>\n",
       "      <td>80.3</td>\n",
       "      <td>294.7</td>\n",
       "      <td>369.0</td>\n",
       "      <td>26.7</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140194</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>654.1</td>\n",
       "      <td>13.8</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>92.2</td>\n",
       "      <td>21.8</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140195 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        HighCalories_Requested  HighProtein_Requested  LowFat_Requested   \n",
       "0                        False                  False             False  \\\n",
       "1                         True                   True              True   \n",
       "2                         True                  False             False   \n",
       "3                         True                   True              True   \n",
       "4                        False                   True              True   \n",
       "...                        ...                    ...               ...   \n",
       "140190                   False                  False              True   \n",
       "140191                   False                   True              True   \n",
       "140192                   False                   True             False   \n",
       "140193                    True                  False             False   \n",
       "140194                   False                  False             False   \n",
       "\n",
       "        Calories  FatContent  SodiumContent  CarbohydrateContent   \n",
       "0          241.3        10.1           13.1                 31.8  \\\n",
       "1          241.3        10.1           13.1                 31.8   \n",
       "2          241.3        10.1           13.1                 31.8   \n",
       "3          241.3        10.1           13.1                 31.8   \n",
       "4          241.3        10.1           13.1                 31.8   \n",
       "...          ...         ...            ...                  ...   \n",
       "140190     121.5         0.5         1175.1                 22.2   \n",
       "140191     652.2        25.8          435.5                 51.9   \n",
       "140192     223.9         9.2          725.9                  7.3   \n",
       "140193    2229.8        80.3          294.7                369.0   \n",
       "140194     654.1        13.8         1114.0                 92.2   \n",
       "\n",
       "        ProteinContent   Like  TestSetId  \n",
       "0                  6.7  False        NaN  \n",
       "1                  6.7  False        NaN  \n",
       "2                  6.7  False        NaN  \n",
       "3                  6.7  False        NaN  \n",
       "4                  6.7  False        NaN  \n",
       "...                ...    ...        ...  \n",
       "140190             7.9   True        NaN  \n",
       "140191            50.1   <NA>     7148.0  \n",
       "140192            26.7   True        NaN  \n",
       "140193            26.7   True        NaN  \n",
       "140194            21.8   True        NaN  \n",
       "\n",
       "[140195 rows x 10 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> Drop\n",
    "merged_df = merged_df.drop(columns=['AuthorId', 'RecipeId', 'TotalTime_Requested', 'TotalTime_Recipe', 'RecipeServings', 'RecipeCategory', 'SaturatedFatContent', 'CholesterolContent', 'FiberContent', 'SugarContent', 'LowSugar_Requested', 'HighFiber_Requested', 'Age'])\n",
    "# One-Hot_encoding\n",
    "# merged_df = pd.get_dummies(merged_df, columns=['user_diet_category', 'recipe_diet_category'])\n",
    "\n",
    "# drop user_diet_category, recipe_diet_category\n",
    "merged_df = merged_df.drop(columns=['user_diet_category', 'recipe_diet_category'])\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column merged_df['same_category]: \n",
    "    # = 1 if recipe_category == Ominvore but user_diet_category == Vegetarian or Vegan\n",
    "    # = 1 if recipe_category == Vegetarian but user_diet_category == Vegan \n",
    "    # else 0 \n",
    "\n",
    "#merged_df['same_category'] = merged_df.apply(lambda row: 1 if (row['recipe_diet_category'] == 'Omnivore' and (row['user_diet_category'] == 'Vegetarian' or row['user_diet_category'] == 'Vegan')) \n",
    "#                    or ((row['recipe_diet_category'] == 'Vegetarian' or row['recipe_diet_category'] == 'Omnivore') and row['user_diet_category'] == 'Vegan') else 0, axis=1)\n",
    "\n",
    "# corr between Like and same_category\n",
    "#merged_df[['Like', 'same_category']].corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot corr for whole merged_df\n",
    "#plot_corr(merged_df.drop(columns=['user_diet_category', 'recipe_diet_category']), title=\"Full data without categorical columns\", is_like=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   HighCalories_Requested  140195 non-null  boolean\n",
      " 1   HighProtein_Requested   140195 non-null  boolean\n",
      " 2   LowFat_Requested        140195 non-null  boolean\n",
      " 3   Calories                140195 non-null  float64\n",
      " 4   FatContent              140195 non-null  float64\n",
      " 5   SodiumContent           140195 non-null  float64\n",
      " 6   CarbohydrateContent     140195 non-null  float64\n",
      " 7   ProteinContent          140195 non-null  float64\n",
      " 8   Like                    97381 non-null   boolean\n",
      " 9   TestSetId               42814 non-null   float64\n",
      "dtypes: boolean(4), float64(6)\n",
      "memory usage: 7.5 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>Like</th>\n",
       "      <th>TestSetId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighCalories_Requested  HighProtein_Requested  LowFat_Requested  Calories   \n",
       "0                   False                  False             False     241.3  \\\n",
       "1                    True                   True              True     241.3   \n",
       "2                    True                  False             False     241.3   \n",
       "3                    True                   True              True     241.3   \n",
       "4                   False                   True              True     241.3   \n",
       "\n",
       "   FatContent  SodiumContent  CarbohydrateContent  ProteinContent   Like   \n",
       "0        10.1           13.1                 31.8             6.7  False  \\\n",
       "1        10.1           13.1                 31.8             6.7  False   \n",
       "2        10.1           13.1                 31.8             6.7  False   \n",
       "3        10.1           13.1                 31.8             6.7  False   \n",
       "4        10.1           13.1                 31.8             6.7  False   \n",
       "\n",
       "   TestSetId  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.info()\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Spliting : Test - Train - Val \n",
    "\n",
    "<span style=\"color:red\">\n",
    "\n",
    "- randomly split with shuffle=True  (Note: remember the random_state number to be able to reproduce the split) \n",
    "- k-cross validation? \n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87642 entries, 34459 to 102791\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   HighCalories_Requested  87642 non-null  boolean\n",
      " 1   HighProtein_Requested   87642 non-null  boolean\n",
      " 2   LowFat_Requested        87642 non-null  boolean\n",
      " 3   Calories                87642 non-null  float64\n",
      " 4   FatContent              87642 non-null  float64\n",
      " 5   SodiumContent           87642 non-null  float64\n",
      " 6   CarbohydrateContent     87642 non-null  float64\n",
      " 7   ProteinContent          87642 non-null  float64\n",
      "dtypes: boolean(3), float64(5)\n",
      "memory usage: 4.5 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TrainVal vs. Test split\n",
    "test_dataframe = merged_df[merged_df['TestSetId'].notna()]\n",
    "#test_dataframe.head(100)\n",
    "\n",
    "# Train vs. Val split\n",
    "train_val_dataframe = merged_df[merged_df['TestSetId'].isna()]\n",
    "\n",
    "# Prepare train val for training \n",
    "train_val_dataframe = merged_df[merged_df['Like'].notna()]\n",
    "train_val_dataframe = train_val_dataframe.drop('TestSetId', axis=1)\n",
    "# put Target (Like column) at the end \n",
    "like_column = train_val_dataframe.pop('Like')\n",
    "train_val_dataframe['Like'] = like_column\n",
    "train_val_dataframe['Like'] = train_val_dataframe['Like'].astype(int)\n",
    "#train_val_dataframe.head(100)\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "  train_test_split(train_val_dataframe.iloc[:, :-1], train_val_dataframe.iloc[:, -1:],\n",
    "                   test_size=0.1, \n",
    "                   shuffle=True,\n",
    "                   random_state=3)\n",
    "\n",
    "X_train.info()\n",
    "#X_val.head()\n",
    "#y_train.info()\n",
    "#y_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Änderung: \n",
    "Bei meta_parameter_grid wurde hinzugefügt:\n",
    "- parameter_grid_gaussianNB\n",
    "- parameter_grid_linearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/Users/woojinko/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Model initialization\n",
    "model_logistic_regression = LogisticRegression(max_iter=100)\n",
    "model_random_forest = RandomForestClassifier()\n",
    "model_gradient_boosting = GradientBoostingClassifier()\n",
    "model_gaussianNB = GaussianNB()\n",
    "model_linearSVC = LinearSVC(max_iter=10000)\n",
    "\n",
    "# Data scaling\n",
    "transform_scaler = StandardScaler()\n",
    "\n",
    "# Dimensionality reduction (optional, based on PCA analysis)\n",
    "transform_pca = PCA()\n",
    "\n",
    "# Pipeline setup\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", transform_scaler),\n",
    "    # Uncomment the following line if PCA is necessary\n",
    "    # (\"pca\", transform_pca),\n",
    "    (\"model\", None)\n",
    "])\n",
    "\n",
    "# Hyperparameters for grid search\n",
    "parameter_grid_preprocessing = {\n",
    "    # \"pca__n_components\": [7, 8],  # Uncomment if using PCA\n",
    "}\n",
    "\n",
    "parameter_grid_gaussianNB = {\n",
    "    \"model\": [model_gaussianNB],\n",
    "    \"model__var_smoothing\": [1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "\n",
    "parameter_grid_linearSVC = {\n",
    "    \"model\": [model_linearSVC],\n",
    "    \"model__C\": [0.1, 1, 10]  # Regularization parameter\n",
    "}\n",
    "\n",
    "parameter_grid_logistic_regression = {\n",
    "    \"model\": [model_logistic_regression],\n",
    "    \"model__C\": [0.1, 1, 10]  # Inverse regularization strength\n",
    "}\n",
    "\n",
    "parameter_grid_gradient_boosting = {\n",
    "    \"model\": [model_gradient_boosting],\n",
    "    \"model__n_estimators\": [10, 20, 30]\n",
    "}\n",
    "\n",
    "# Updated parameter grid for RandomForestClassifier\n",
    "parameter_grid_random_forest = {\n",
    "    \"model\": [RandomForestClassifier()],\n",
    "    \"model__n_estimators\": [100, 200, 500],  # Number of trees in the forest\n",
    "    \"model__max_depth\": [10, 20, 30, None],  # Maximum depth of each tree\n",
    "    \"model__min_samples_split\": [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    \"model__min_samples_leaf\": [1, 2, 4],    # Minimum number of samples required at a leaf node\n",
    "    \"model__max_features\": ['auto', 'sqrt', 'log2'],  # Number of features to consider for the best split\n",
    "    \"model__bootstrap\": [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Combining all parameter grids\n",
    "meta_parameter_grid = [\n",
    "    parameter_grid_logistic_regression,\n",
    "    parameter_grid_random_forest,\n",
    "    parameter_grid_gradient_boosting,\n",
    "    parameter_grid_gaussianNB,\n",
    "    parameter_grid_linearSVC\n",
    "]\n",
    "\n",
    "# Adding preprocessing parameters to each model's grid\n",
    "meta_parameter_grid = [{**parameter_grid_preprocessing, **model_grid}\n",
    "                       for model_grid in meta_parameter_grid]\n",
    "\n",
    "# GridSearchCV setup\n",
    "search = GridSearchCV(\n",
    "    pipeline,\n",
    "    meta_parameter_grid, \n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=2, \n",
    "    cv=5,  # Number of folds for cross-validation\n",
    "    error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# Training and grid search\n",
    "# Replace X_train and y_train with your actual data\n",
    "search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# Uncomment below to print the best parameters\n",
    "print(\"Best parameters:\", search.best_params_, \"(CV score=%0.3f)\" % search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.5644447812507335\n",
      "true     0     1\n",
      "pred            \n",
      "0     8287  1100\n",
      "1      161   191\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of model on test set\n",
    "print(\"Score on test set:\", search.score(X_val, y_val.values.ravel()))\n",
    "\n",
    "# prediction and show contingency table\n",
    "ct = pd.crosstab(search.best_estimator_.predict(X_val), y_val.values.ravel(),\n",
    "                 rownames=[\"pred\"], colnames=[\"true\"])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': LogisticRegression(max_iter=30), 'model__C': 0.1, 'pca__n_components': 7} 0.5020343640293786\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 0.1, 'pca__n_components': 8} 0.5019993593248523\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 1, 'pca__n_components': 7} 0.5020278195267609\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 1, 'pca__n_components': 8} 0.5020644830235109\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 10, 'pca__n_components': 7} 0.5020278195267609\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 10, 'pca__n_components': 8} 0.5020210425369774\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 12, 'model__n_estimators': 10, 'pca__n_components': 7} 0.5517508573803369\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 12, 'model__n_estimators': 10, 'pca__n_components': 8} 0.5517199251977019\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 12, 'model__n_estimators': 20, 'pca__n_components': 7} 0.5503990538017961\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 12, 'model__n_estimators': 20, 'pca__n_components': 8} 0.5462299325655673\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 12, 'model__n_estimators': 50, 'pca__n_components': 7} 0.5486207152995773\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 12, 'model__n_estimators': 50, 'pca__n_components': 8} 0.5451924826281698\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 13, 'model__n_estimators': 10, 'pca__n_components': 7} 0.5577600315952148\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 13, 'model__n_estimators': 10, 'pca__n_components': 8} 0.5540362930993301\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 13, 'model__n_estimators': 20, 'pca__n_components': 7} 0.5550945487650257\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 13, 'model__n_estimators': 20, 'pca__n_components': 8} 0.5509185515687497\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 13, 'model__n_estimators': 50, 'pca__n_components': 7} 0.5529691837941184\n",
      "{'model': RandomForestClassifier(max_depth=13, n_estimators=10), 'model__max_depth': 13, 'model__n_estimators': 50, 'pca__n_components': 8} 0.5498036787942093\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 10, 'pca__n_components': 7} 0.5\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 10, 'pca__n_components': 8} 0.5\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 20, 'pca__n_components': 7} 0.503710063171852\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 20, 'pca__n_components': 8} 0.5042632432547433\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 30, 'pca__n_components': 7} 0.5070016605418852\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 30, 'pca__n_components': 8} 0.5068277952582714\n",
      "{'model': GaussianNB(), 'model__var_smoothing': 1e-09, 'pca__n_components': 7} 0.5185342483820602\n",
      "{'model': GaussianNB(), 'model__var_smoothing': 1e-09, 'pca__n_components': 8} 0.5183915797116907\n",
      "{'model': GaussianNB(), 'model__var_smoothing': 1e-08, 'pca__n_components': 7} 0.5185342483820602\n",
      "{'model': GaussianNB(), 'model__var_smoothing': 1e-08, 'pca__n_components': 8} 0.5183915797116907\n",
      "{'model': GaussianNB(), 'model__var_smoothing': 1e-07, 'pca__n_components': 7} 0.5185342483820602\n",
      "{'model': GaussianNB(), 'model__var_smoothing': 1e-07, 'pca__n_components': 8} 0.5183915797116907\n",
      "{'model': LinearSVC(), 'model__C': 0.1, 'pca__n_components': 7} 0.5012593842764947\n",
      "{'model': LinearSVC(), 'model__C': 0.1, 'pca__n_components': 8} 0.5012738496423397\n",
      "{'model': LinearSVC(), 'model__C': 1, 'pca__n_components': 7} 0.5016865070297165\n",
      "{'model': LinearSVC(), 'model__C': 1, 'pca__n_components': 8} 0.5017778462810674\n",
      "{'model': LinearSVC(), 'model__C': 10, 'pca__n_components': 7} 0.5040230256709737\n",
      "{'model': LinearSVC(), 'model__C': 10, 'pca__n_components': 8} 0.5030593509571415\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# (optional, if you're curious) for a detailed look on the performance of the different models\n",
    "def get_search_score_overview():\n",
    "  for c,s in zip(search.cv_results_[\"params\"],search.cv_results_[\"mean_test_score\"]):\n",
    "      print(c, s)\n",
    "\n",
    "print(get_search_score_overview())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HighCalories_Requested  HighProtein_Requested  LowFat_Requested  Calories   \n",
       "5                    False                   True             False     241.3  \\\n",
       "7                    False                  False             False     241.3   \n",
       "8                    False                  False             False     241.3   \n",
       "14                   False                   True             False     241.3   \n",
       "15                   False                   True             False     241.3   \n",
       "\n",
       "    FatContent  SodiumContent  CarbohydrateContent  ProteinContent  \n",
       "5         10.1           13.1                 31.8             6.7  \n",
       "7         10.1           13.1                 31.8             6.7  \n",
       "8         10.1           13.1                 31.8             6.7  \n",
       "14        10.1           13.1                 31.8             6.7  \n",
       "15        10.1           13.1                 31.8             6.7  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare test data for prediction\n",
    "test_set_id = test_dataframe.pop('TestSetId')\n",
    "test_dataframe = test_dataframe.drop('Like', axis=1)\n",
    "test_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "model = search.best_estimator_ \n",
    "test_dataframe[\"Like\"] = model.predict(test_dataframe)\n",
    "\n",
    "#TODO: \n",
    "\n",
    "# prediction := List if Like \n",
    "# test_set_id := List of test ID\n",
    "\n",
    "# write to CSV file in the same order  (den Code unten anpassenm)\n",
    "# 1.ID  1.Like \n",
    "# 2.ID  2.Like\n",
    "\n",
    "output = pd.DataFrame(test_dataframe[\"Like\"])\n",
    "output[\"id\"] = test_set_id.astype(\"int\")\n",
    "\n",
    "output = output.rename(columns={'Like': 'prediction'})\n",
    "output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "\n",
    "output.to_csv('recipe_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume that our id column is the index of the dataframe\n",
    "\n",
    "# print(test_dataframe)\n",
    "#output = pd.DataFrame(test_dataframe[\"Like\"])\n",
    "# output = output.reset_index(drop=True)\n",
    "#output[\"id\"] = output.index + 1\n",
    "#output = output.rename(columns={'Like': 'prediction'})\n",
    "#output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "# output length\n",
    "#print(len(output))\n",
    "#output.to_csv('recipe_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
