{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "#import sweetviz as sv\n",
    "#import shap\n",
    "#from ydata_profiling import ProfileReport\n",
    "\n",
    "\n",
    "seed = 2024  #seed = 2024: train model as stated in example_crisp_dm_pipeline.ipynb\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Data Cleaning: Readin data and preprocessing individual table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75604 entries, 0 to 75603\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype   \n",
      "---  ------                --------------  -----   \n",
      " 0   RecipeId              75604 non-null  int64   \n",
      " 1   RecipeCategory        75604 non-null  category\n",
      " 2   Calories              75604 non-null  float64 \n",
      " 3   FatContent            75604 non-null  float64 \n",
      " 4   SaturatedFatContent   75604 non-null  float64 \n",
      " 5   CholesterolContent    75604 non-null  float64 \n",
      " 6   SodiumContent         75604 non-null  float64 \n",
      " 7   CarbohydrateContent   75604 non-null  float64 \n",
      " 8   FiberContent          75604 non-null  float64 \n",
      " 9   SugarContent          75604 non-null  float64 \n",
      " 10  ProteinContent        75604 non-null  float64 \n",
      " 11  RecipeServings        48891 non-null  float64 \n",
      " 12  recipe_diet_category  75604 non-null  category\n",
      " 13  TotalTime_Recipe      75604 non-null  int64   \n",
      "dtypes: category(2), float64(10), int64(2)\n",
      "memory usage: 7.1 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>RecipeCategory</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SaturatedFatContent</th>\n",
       "      <th>CholesterolContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>FiberContent</th>\n",
       "      <th>SugarContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>RecipeServings</th>\n",
       "      <th>recipe_diet_category</th>\n",
       "      <th>TotalTime_Recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73440</td>\n",
       "      <td>Other</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>1800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>365718</td>\n",
       "      <td>Other</td>\n",
       "      <td>370.8</td>\n",
       "      <td>17.5</td>\n",
       "      <td>7.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>553.3</td>\n",
       "      <td>44.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141757</td>\n",
       "      <td>Other</td>\n",
       "      <td>377.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>10.5</td>\n",
       "      <td>45.7</td>\n",
       "      <td>1501.8</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>12.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>6300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>280351</td>\n",
       "      <td>Other</td>\n",
       "      <td>282.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>10.3</td>\n",
       "      <td>50.5</td>\n",
       "      <td>630.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>11.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Omnivore</td>\n",
       "      <td>19800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180505</td>\n",
       "      <td>Other</td>\n",
       "      <td>257.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>110.7</td>\n",
       "      <td>160.9</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>30.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>5400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecipeId RecipeCategory  Calories  FatContent  SaturatedFatContent  \\\n",
       "0     73440          Other     241.3        10.1                  1.2   \n",
       "1    365718          Other     370.8        17.5                  7.2   \n",
       "2    141757          Other     377.6        20.9                 10.5   \n",
       "3    280351          Other     282.8        16.5                 10.3   \n",
       "4    180505          Other     257.5         8.6                  2.4   \n",
       "\n",
       "   CholesterolContent  SodiumContent  CarbohydrateContent  FiberContent  \\\n",
       "0                 0.0           13.1                 31.8           2.3   \n",
       "1                22.9          553.3                 44.3           1.6   \n",
       "2                45.7         1501.8                 36.6           3.8   \n",
       "3                50.5          630.2                 22.8           2.3   \n",
       "4               110.7          160.9                 39.8           0.4   \n",
       "\n",
       "   SugarContent  ProteinContent  RecipeServings recipe_diet_category  \\\n",
       "0           1.4             6.7             9.0           Vegetarian   \n",
       "1           2.2             9.4             8.0             Omnivore   \n",
       "2           6.1            12.9             8.0           Vegetarian   \n",
       "3           2.7            11.7             6.0             Omnivore   \n",
       "4          30.2             6.3             6.0                Vegan   \n",
       "\n",
       "   TotalTime_Recipe  \n",
       "0              1800  \n",
       "1              4200  \n",
       "2              6300  \n",
       "3             19800  \n",
       "4              5400  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_recipes = pd.read_csv('data/recipes.csv')\n",
    "\n",
    "# Consolidated Non-Vegetarian Keywords\n",
    "non_vegetarian_keywords = list(set([\n",
    "    'flounder', 'lobsters', 'lump', 'rack', 'shank', 'steak', 'scallops', 'alligator', \n",
    "    'livers', 'roe', 'ham', 'turkey', 'chicken', 'duck', 'bacon', 'tuna', 'swordfish', \n",
    "    'lobster', 'meatballs', 'salmon', 'sweetbreads', 'breasts', 'chicken-flavored', \n",
    "    'ducklings', 'drumstick', 'liver', 'shanks', 'rabbit', 'poultry', 'herring', \n",
    "    'mussels', 'clams', 'squid', 'pork', 'veal', 'haddock', 'chorizo', 'chihuahua', \n",
    "    'eel', 'stuffing', 'cod', 'gelatin', 'sausage', 'curd', 'thighs', 'lox', 'cabbage', \n",
    "    'wonton', 'bone', 'giblets', 'pheasant', 'quail', 'shrimp', 'fish', 'sole', \n",
    "    'gizzard', 'Canadian', 'pesto', 'truffles', 'anchovies', 'venison', 'pheasants', \n",
    "    'tenderloin', 'meats', 'tripe', 'breast', 'wings', 'ribs', 'sausages', 'trout', \n",
    "    'oysters', 'octopus', 'crab', 'prawns', 'catfish', 'sardines', 'mahi', 'halibut', \n",
    "    'bass', 'perch', 'tilapia', 'grouper'\n",
    "]))\n",
    "\n",
    "# Consolidated Non-Vegan Keywords\n",
    "non_vegan_keywords = list(set([\n",
    "    'milk', 'cheese', 'butter', 'egg', 'honey', 'mozzarella-cheddar', 'cream', 'whip', \n",
    "    'jarlsberg', 'fontina', 'ham', 'cheesecake', 'hollandaise', 'caviar', 'creamRegular', \n",
    "    'custard', 'yogurt', 'gouda', 'margarine', 'beef', 'salmon', 'sour', 'bisquick', \n",
    "    'carton', 'cotija', 'creme', 'buttercream', 'buttermilk', 'ricotta', 'cottage', \n",
    "    'eggs', 'mayonnaise', 'eggshells', 'lactose-free', 'skim', 'ghee', 'mascarpone', \n",
    "    'alfredo', 'whey', 'casein', 'lactose', 'albumin', 'bechamel', 'sour cream', \n",
    "    'cream cheese', 'feta', 'gorgonzola', 'parmesan', 'mozzarella', 'cheddar', 'brie', \n",
    "    'camembert', 'roquefort', 'stilton', 'blue cheese', 'colby', 'monterey jack', \n",
    "    'swiss cheese', 'provolone', 'edam', 'havarti', 'pecorino', 'asiago', 'emmental', \n",
    "    'gruyere', 'halloumi', 'manchego', 'paneer', 'queso fresco', 'ricotta salata', \n",
    "    'romano', 'taleggio', 'vacherin', 'milk chocolate', 'whey protein', 'casein protein', \n",
    "    'egg noodles', 'egg whites', 'egg yolks', 'hollandaise sauce', 'aioli', 'flan', \n",
    "    'quiche', 'meringue', 'pavlova', 'egg wash', 'frittata', 'omelette', 'scrambled eggs', \n",
    "    'poached eggs', 'hard-boiled eggs', 'deviled eggs', 'eggnog', 'brioche', 'challah', \n",
    "    'pound cake', 'sponge cake', 'angel food cake', 'ladyfingers', 'mousse', 'souffle', \n",
    "    'creme brulee', 'panna cotta', 'tiramisu', 'yorkshire pudding', 'beef broth', \n",
    "    'chicken broth', 'fish sauce', 'oyster sauce', 'worcestershire sauce', 'caesar dressing', \n",
    "    'carbonara sauce', 'béarnaise sauce', 'gravlax', 'smoked salmon', 'caviar', 'anchovy paste', \n",
    "    'fish stock'\n",
    "]))\n",
    "\n",
    "\n",
    "# Function to check if a RecipeIngredientParts is vegetarian\n",
    "def is_vegetarian(ingredient):\n",
    "    for keyword in non_vegetarian_keywords:\n",
    "        if keyword in ingredient.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Function to check if a RecipeIngredientParts is vegan\n",
    "def is_vegan(ingredient):\n",
    "    for keyword in non_vegan_keywords:\n",
    "        if keyword in ingredient.lower():\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Apply the is_vegetarian function to the RecipeIngredientParts column\n",
    "df_recipes['is_vegetarian'] = df_recipes['RecipeIngredientParts'].apply(is_vegetarian)\n",
    "\n",
    "# Apply the is_vegan function to the RecipeIngredientParts column\n",
    "df_recipes['is_vegan'] = df_recipes['RecipeIngredientParts'].apply(is_vegan)\n",
    "\n",
    "# Map the diet category based on the is_vegetarian and is_vegan columns\n",
    "df_recipes['diet_category'] = df_recipes.apply(lambda row: 'Vegetarian' if row['is_vegetarian'] else 'Vegan' if row['is_vegan'] else 'Omnivore', axis=1)\n",
    "\n",
    "# create TotalTime_Recipe column\n",
    "df_recipes['TotalTime_Recipe'] = df_recipes['CookTime'] + df_recipes['PrepTime']\n",
    "\n",
    "# drop columns\n",
    "df_recipes = df_recipes.drop(columns=['Name', 'CookTime', 'PrepTime', 'RecipeIngredientParts', 'RecipeIngredientQuantities', 'RecipeYield', 'is_vegetarian', 'is_vegan'])\n",
    "# dtype conversion\n",
    "df_recipes[\"RecipeCategory\"] = df_recipes[\"RecipeCategory\"].astype(\"category\")\n",
    "df_recipes[\"diet_category\"] = df_recipes[\"diet_category\"].astype(\"category\")\n",
    "# rename columns\n",
    "df_recipes = df_recipes.rename(columns={\"diet_category\": \"recipe_diet_category\"})\n",
    "\n",
    "df_recipes.info()\n",
    "df_recipes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorId    0\n",
      "Diet        1\n",
      "Age         0\n",
      "dtype: int64\n",
      "['Vegetarian' 'Vegan' 'Omnivore' nan]\n",
      "AuthorId    0\n",
      "Diet        0\n",
      "Age         0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271907 entries, 0 to 271906\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count   Dtype   \n",
      "---  ------              --------------   -----   \n",
      " 0   AuthorId            271907 non-null  object  \n",
      " 1   user_diet_category  271907 non-null  category\n",
      " 2   Age                 271907 non-null  int64   \n",
      "dtypes: category(1), int64(1), object(1)\n",
      "memory usage: 4.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>user_diet_category</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000120E</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000014D</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000015A</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000016E</td>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000027E</td>\n",
       "      <td>Vegan</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AuthorId user_diet_category  Age\n",
       "0  10000120E         Vegetarian   46\n",
       "1   1000014D              Vegan   18\n",
       "2   1000015A         Vegetarian   58\n",
       "3   1000016E         Vegetarian   32\n",
       "4   1000027E              Vegan   61"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_diet = pd.read_csv('data/diet.csv')\n",
    "\n",
    "# chcek for missing values in the data\n",
    "print(df_diet.isnull().sum())\n",
    "\n",
    "# replace missing value in Diet with \"Omnivore\"\n",
    "print(df_diet[\"Diet\"].unique())\n",
    "df_diet[\"Diet\"] = df_diet[\"Diet\"].fillna(\"Omnivore\")\n",
    "\n",
    "# check again\n",
    "print(df_diet.isnull().sum())\n",
    "\n",
    "# Change data type of Diet to category\n",
    "df_diet[\"Diet\"] = df_diet[\"Diet\"].astype(\"category\")\n",
    "\n",
    "# rename the column Diet to diet_category\n",
    "df_diet = df_diet.rename(columns={\"Diet\": \"user_diet_category\"})\n",
    "\n",
    "df_diet.info()\n",
    "df_diet.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthorId        0\n",
      "RecipeId        0\n",
      "Time            0\n",
      "HighCalories    0\n",
      "HighProtein     0\n",
      "LowFat          0\n",
      "LowSugar        0\n",
      "HighFiber       0\n",
      "dtype: int64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   AuthorId                140195 non-null  object \n",
      " 1   RecipeId                140195 non-null  int64  \n",
      " 2   TotalTime_Requested     140195 non-null  float64\n",
      " 3   HighCalories_Requested  140195 non-null  boolean\n",
      " 4   HighProtein_Requested   140195 non-null  boolean\n",
      " 5   LowFat_Requested        140195 non-null  boolean\n",
      " 6   LowSugar_Requested      140195 non-null  boolean\n",
      " 7   HighFiber_Requested     140195 non-null  boolean\n",
      "dtypes: boolean(5), float64(1), int64(1), object(1)\n",
      "memory usage: 4.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>TotalTime_Requested</th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>LowSugar_Requested</th>\n",
       "      <th>HighFiber_Requested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001012259B</td>\n",
       "      <td>73440</td>\n",
       "      <td>1799.950949</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437641B</td>\n",
       "      <td>365718</td>\n",
       "      <td>4201.820980</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1803340263D</td>\n",
       "      <td>141757</td>\n",
       "      <td>6299.861496</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>854048B</td>\n",
       "      <td>280351</td>\n",
       "      <td>19801.365796</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2277685E</td>\n",
       "      <td>180505</td>\n",
       "      <td>5400.093457</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AuthorId  RecipeId  TotalTime_Requested  HighCalories_Requested  \\\n",
       "0  2001012259B     73440          1799.950949                   False   \n",
       "1      437641B    365718          4201.820980                   False   \n",
       "2  1803340263D    141757          6299.861496                   False   \n",
       "3      854048B    280351         19801.365796                   False   \n",
       "4     2277685E    180505          5400.093457                   False   \n",
       "\n",
       "   HighProtein_Requested  LowFat_Requested  LowSugar_Requested  \\\n",
       "0                  False             False                True   \n",
       "1                   True             False               False   \n",
       "2                  False              True               False   \n",
       "3                   True              True                True   \n",
       "4                  False             False                True   \n",
       "\n",
       "   HighFiber_Requested  \n",
       "0                False  \n",
       "1                 True  \n",
       "2                False  \n",
       "3                 True  \n",
       "4                False  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_requests = pd.read_csv('data/requests.csv')\n",
    "\n",
    "# check for missing values\n",
    "print(df_requests.isnull().sum())\n",
    "\n",
    "#dtype\n",
    "df_requests['HighCalories'] = df_requests['HighCalories'].astype('boolean')\n",
    "\n",
    "df_requests['HighProtein'] = df_requests['HighProtein'].replace({'Indifferent': False, 'Yes': True})\n",
    "df_requests['HighProtein'] = df_requests['HighProtein'].astype('boolean')\n",
    "\n",
    "df_requests['LowFat'] = df_requests['LowFat'].astype('boolean')\n",
    "\n",
    "df_requests['LowSugar'] = df_requests['LowSugar'].replace({'Indifferent': False, '0': True})\n",
    "df_requests['LowSugar'] = df_requests['LowSugar'].astype('boolean')\n",
    "\n",
    "df_requests['HighFiber'] = df_requests['HighFiber'].astype('boolean')\n",
    "\n",
    "# rename columns\n",
    "df_requests.rename(columns={'Time': 'TotalTime_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'HighCalories': 'HighCalories_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'HighProtein': 'HighProtein_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'LowFat': 'LowFat_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'LowSugar': 'LowSugar_Requested'}, inplace=True)\n",
    "df_requests.rename(columns={'HighFiber': 'HighFiber_Requested'}, inplace=True)\n",
    "\n",
    "df_requests.info() \n",
    "df_requests.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   AuthorId   140195 non-null  object \n",
      " 1   RecipeId   140195 non-null  int64  \n",
      " 2   Like       97381 non-null   boolean\n",
      " 3   TestSetId  42814 non-null   float64\n",
      "dtypes: boolean(1), float64(1), int64(1), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9c/9ttnz44d25g9j7t3x_fdr1d40000gn/T/ipykernel_70418/4131158636.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_reviews = pd.read_csv('data/reviews.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AuthorId</th>\n",
       "      <th>RecipeId</th>\n",
       "      <th>Like</th>\n",
       "      <th>TestSetId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2492191A</td>\n",
       "      <td>33671</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002019979A</td>\n",
       "      <td>92647</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>408594E</td>\n",
       "      <td>161770</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001625557E</td>\n",
       "      <td>108231</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001427116E</td>\n",
       "      <td>71109</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      AuthorId  RecipeId  Like  TestSetId\n",
       "0     2492191A     33671  <NA>        1.0\n",
       "1  2002019979A     92647  <NA>        2.0\n",
       "2      408594E    161770  <NA>        3.0\n",
       "3  2001625557E    108231  <NA>        4.0\n",
       "4  2001427116E     71109  <NA>        5.0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews = pd.read_csv('data/reviews.csv')\n",
    "\n",
    "#sns.countplot(data=df_reviews, x='Rating')  # Rating is only 2 except 2 rows -> drop Rating column\n",
    "df_reviews = df_reviews.drop('Rating', axis=1)\n",
    "\n",
    "# check for missing values\n",
    "# print(df_reviews.isnull().sum())\n",
    "\n",
    "# dtype \n",
    "df_reviews['Like'] = df_reviews['Like'].astype('boolean')\n",
    "\n",
    "df_reviews.info()\n",
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aggregation (Merge the tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep all request, add info about custormers diet when exit -> df_diet right_join df_requests\n",
    "merged_df_diet_request = df_diet.merge(df_requests, on='AuthorId', how='right')\n",
    "#merged_df_diet_request.head(100)\n",
    "\n",
    "# request without matched recipe, or recipe without request is useless  -> normal join \n",
    "merged_df_diet_request_recipes = merged_df_diet_request.merge(df_recipes, on='RecipeId')\n",
    "#merged_df_diet_request_recipes.tail(100)\n",
    "\n",
    "# review without request,recipes is useless -> left \n",
    "merged_df_diet_request_recipes_reviews = merged_df_diet_request_recipes.merge(df_reviews, on=['RecipeId', 'AuthorId'], how='left')\n",
    "#merged_df_diet_request_recipes_reviews.info()\n",
    "\n",
    "merged_df = merged_df_diet_request_recipes_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Data Cleaning (after merged) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ishanjainoffical.medium.com/choosing-the-right-correlation-pearson-vs-spearman-vs-kendalls-tau-02dc7d7dd01d\n",
    "def plot_corr(df, title, is_like=True):\n",
    "    if 'Like' in df:\n",
    "        df = df[df['Like'] == 1]\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(25, 7))\n",
    "    nutrients_corr = df.corr(method='kendall') \n",
    "    mask = np.triu(np.ones_like(nutrients_corr, dtype=bool))\n",
    "    cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    sns.heatmap(nutrients_corr, mask=mask, cmap=cmap, annot=True, fmt=\".2f\", ax=ax1, center=0)\n",
    "    ax1.set_title(title + ' - kendall', fontsize=16)\n",
    "    nutrients_corr = df.corr(method='pearson')\n",
    "    mask = np.triu(np.ones_like(nutrients_corr, dtype=bool))\n",
    "    cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    sns.heatmap(nutrients_corr, mask=mask, cmap=cmap, annot=True, fmt=\".2f\", ax=ax2, center=0)\n",
    "    ax2.set_title(title + ' - pearson', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> Drop\n",
    "merged_df = merged_df.drop(columns=['AuthorId', 'RecipeId', 'TotalTime_Requested', 'TotalTime_Recipe', 'RecipeServings', 'RecipeCategory', 'SaturatedFatContent', 'CholesterolContent', 'FiberContent', 'SugarContent', 'LowSugar_Requested', 'HighFiber_Requested', 'Age'])\n",
    "# One-Hot_encoding\n",
    "merged_df = pd.get_dummies(merged_df, columns=['user_diet_category', 'recipe_diet_category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column merged_df['same_category]: \n",
    "    # = 1 if recipe_category == Ominvore but user_diet_category == Vegetarian or Vegan\n",
    "    # = 1 if recipe_category == Vegetarian but user_diet_category == Vegan \n",
    "    # else 0 \n",
    "\n",
    "#merged_df['same_category'] = merged_df.apply(lambda row: 1 if (row['recipe_diet_category'] == 'Omnivore' and (row['user_diet_category'] == 'Vegetarian' or row['user_diet_category'] == 'Vegan')) \n",
    "#                    or ((row['recipe_diet_category'] == 'Vegetarian' or row['recipe_diet_category'] == 'Omnivore') and row['user_diet_category'] == 'Vegan') else 0, axis=1)\n",
    "\n",
    "# corr between Like and same_category\n",
    "#merged_df[['Like', 'same_category']].corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot corr for whole merged_df\n",
    "#plot_corr(merged_df.drop(columns=['user_diet_category', 'recipe_diet_category']), title=\"Full data without categorical columns\", is_like=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 140195 entries, 0 to 140194\n",
      "Data columns (total 16 columns):\n",
      " #   Column                           Non-Null Count   Dtype  \n",
      "---  ------                           --------------   -----  \n",
      " 0   HighCalories_Requested           140195 non-null  boolean\n",
      " 1   HighProtein_Requested            140195 non-null  boolean\n",
      " 2   LowFat_Requested                 140195 non-null  boolean\n",
      " 3   Calories                         140195 non-null  float64\n",
      " 4   FatContent                       140195 non-null  float64\n",
      " 5   SodiumContent                    140195 non-null  float64\n",
      " 6   CarbohydrateContent              140195 non-null  float64\n",
      " 7   ProteinContent                   140195 non-null  float64\n",
      " 8   Like                             97381 non-null   boolean\n",
      " 9   TestSetId                        42814 non-null   float64\n",
      " 10  user_diet_category_Omnivore      140195 non-null  bool   \n",
      " 11  user_diet_category_Vegan         140195 non-null  bool   \n",
      " 12  user_diet_category_Vegetarian    140195 non-null  bool   \n",
      " 13  recipe_diet_category_Omnivore    140195 non-null  bool   \n",
      " 14  recipe_diet_category_Vegan       140195 non-null  bool   \n",
      " 15  recipe_diet_category_Vegetarian  140195 non-null  bool   \n",
      "dtypes: bool(6), boolean(4), float64(6)\n",
      "memory usage: 8.3 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>Like</th>\n",
       "      <th>TestSetId</th>\n",
       "      <th>user_diet_category_Omnivore</th>\n",
       "      <th>user_diet_category_Vegan</th>\n",
       "      <th>user_diet_category_Vegetarian</th>\n",
       "      <th>recipe_diet_category_Omnivore</th>\n",
       "      <th>recipe_diet_category_Vegan</th>\n",
       "      <th>recipe_diet_category_Vegetarian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HighCalories_Requested  HighProtein_Requested  LowFat_Requested  Calories  \\\n",
       "0                   False                  False             False     241.3   \n",
       "1                    True                   True              True     241.3   \n",
       "2                    True                  False             False     241.3   \n",
       "3                    True                   True              True     241.3   \n",
       "4                   False                   True              True     241.3   \n",
       "\n",
       "   FatContent  SodiumContent  CarbohydrateContent  ProteinContent   Like  \\\n",
       "0        10.1           13.1                 31.8             6.7  False   \n",
       "1        10.1           13.1                 31.8             6.7  False   \n",
       "2        10.1           13.1                 31.8             6.7  False   \n",
       "3        10.1           13.1                 31.8             6.7  False   \n",
       "4        10.1           13.1                 31.8             6.7  False   \n",
       "\n",
       "   TestSetId  user_diet_category_Omnivore  user_diet_category_Vegan  \\\n",
       "0        NaN                        False                     False   \n",
       "1        NaN                        False                     False   \n",
       "2        NaN                        False                     False   \n",
       "3        NaN                        False                      True   \n",
       "4        NaN                        False                      True   \n",
       "\n",
       "   user_diet_category_Vegetarian  recipe_diet_category_Omnivore  \\\n",
       "0                           True                          False   \n",
       "1                           True                          False   \n",
       "2                           True                          False   \n",
       "3                          False                          False   \n",
       "4                          False                          False   \n",
       "\n",
       "   recipe_diet_category_Vegan  recipe_diet_category_Vegetarian  \n",
       "0                       False                             True  \n",
       "1                       False                             True  \n",
       "2                       False                             True  \n",
       "3                       False                             True  \n",
       "4                       False                             True  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.info()\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Spliting : Test - Train - Val \n",
    "\n",
    "<span style=\"color:red\">\n",
    "\n",
    "- randomly split with shuffle=True  (Note: remember the random_state number to be able to reproduce the split) \n",
    "- k-cross validation? \n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87642 entries, 34459 to 102791\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   Like    87642 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TrainVal vs. Test split\n",
    "test_dataframe = merged_df[merged_df['TestSetId'].notna()]\n",
    "#test_dataframe.head(100)\n",
    "\n",
    "# Train vs. Val split\n",
    "train_val_dataframe = merged_df[merged_df['TestSetId'].isna()]\n",
    "\n",
    "# Prepare train val for training \n",
    "train_val_dataframe = merged_df[merged_df['Like'].notna()]\n",
    "train_val_dataframe = train_val_dataframe.drop('TestSetId', axis=1)\n",
    "# put Target (Like column) at the end \n",
    "like_column = train_val_dataframe.pop('Like')\n",
    "train_val_dataframe['Like'] = like_column\n",
    "train_val_dataframe['Like'] = train_val_dataframe['Like'].astype(int)\n",
    "#train_val_dataframe.head(100)\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "  train_test_split(train_val_dataframe.iloc[:, :-1], train_val_dataframe.iloc[:, -1:],\n",
    "                   test_size=0.1, \n",
    "                   shuffle=True,\n",
    "                   random_state=3)\n",
    "\n",
    "#X_train.head()\n",
    "#X_val.head()\n",
    "y_train.info()\n",
    "#y_val.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 78\u001b[0m\n\u001b[1;32m     69\u001b[0m search \u001b[39m=\u001b[39m GridSearchCV(pipeline,\n\u001b[1;32m     70\u001b[0m                       meta_parameter_grid, \n\u001b[1;32m     71\u001b[0m                       scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbalanced_accuracy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m                       error_score\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m )\n\u001b[1;32m     77\u001b[0m \u001b[39m# here, the actual training and grid search happens\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m search\u001b[39m.\u001b[39;49mfit(X_train, y_train\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mravel())\n\u001b[1;32m     80\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mbest parameter:\u001b[39m\u001b[39m\"\u001b[39m, search\u001b[39m.\u001b[39mbest_params_ ,\u001b[39m\"\u001b[39m\u001b[39m(CV score=\u001b[39m\u001b[39m%0.3f\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m search\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1421\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1422\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[39m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[39m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[39m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[39m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[39m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout) \u001b[39m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   1708\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[39m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB , MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_logistic_regression = LogisticRegression(max_iter=30)\n",
    "model_random_forest = RandomForestClassifier()\n",
    "model_gradient_boosting = GradientBoostingClassifier()\n",
    "model_gauusianNB = GaussianNB()\n",
    "model_linearSVC = LinearSVC()\n",
    "\n",
    "# data scaling\n",
    "transform_scaler = StandardScaler()\n",
    "\n",
    "# dimensionality reduction\n",
    "transform_pca = PCA()\n",
    "\n",
    "# train the models\n",
    "pipeline = Pipeline(steps=[(\"scaler\", transform_scaler), \n",
    "                           (\"pca\", transform_pca),\n",
    "                           (\"model\", None)])\n",
    "\n",
    "parameter_grid_preprocessing = {\n",
    "  \"pca__n_components\" : [1, 2, 3, 4],\n",
    "}\n",
    "\n",
    "parameter_grid_gaussianNB = {\n",
    "  \"model\" : [model_gauusianNB],\n",
    "  \"model__var_smoothing\": [1e-9, 1e-8, 1e-7]\n",
    "}\n",
    "\n",
    "parameter_grid_linearSVC = {\n",
    "  \"model\" : [model_linearSVC],\n",
    "  \"model__C\": [0.1, 1, 10],  # Regularization parameter\n",
    "  \"model__kernel\": ['linear', 'rbf'],  # Kernel type\n",
    "  \"model__gamma\": ['scale', 'auto']  # Kernel coefficient for 'rbf'\n",
    "}\n",
    "\n",
    "parameter_grid_logistic_regression = {\n",
    "  \"model\" : [model_logistic_regression],\n",
    "  \"model__C\" : [0.1, 1, 10],  # inverse regularization strength\n",
    "}\n",
    "\n",
    "parameter_grid_gradient_boosting = {\n",
    "  \"model\" : [model_gradient_boosting],\n",
    "  \"model__n_estimators\" : [10, 20, 30]\n",
    "}\n",
    "\n",
    "parameter_grid_random_forest = {\n",
    "  \"model\" : [model_random_forest],\n",
    "  \"model__n_estimators\" : [10, 20, 50],  # number of max trees in the forest\n",
    "  \"model__max_depth\" : [2, 3, 4],\n",
    "}\n",
    "\n",
    "meta_parameter_grid = [parameter_grid_logistic_regression,\n",
    "                       parameter_grid_random_forest,\n",
    "                       parameter_grid_gradient_boosting]\n",
    "\n",
    "meta_parameter_grid = [{**parameter_grid_preprocessing, **model_grid}\n",
    "                       for model_grid in meta_parameter_grid]\n",
    "\n",
    "search = GridSearchCV(pipeline,\n",
    "                      meta_parameter_grid, \n",
    "                      scoring=\"balanced_accuracy\",\n",
    "                      n_jobs=2, \n",
    "                      cv=5,  # number of folds for cross-validation \n",
    "                      error_score=\"raise\"\n",
    ")\n",
    "\n",
    "# here, the actual training and grid search happens\n",
    "search.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "print(\"best parameter:\", search.best_params_ ,\"(CV score=%0.3f)\" % search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on test set: 0.989733233713708\n",
      "true   False  True \n",
      "pred               \n",
      "False   2999      4\n",
      "True      61   6675\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance of model on test set\n",
    "print(\"Score on test set:\", search.score(X_val, y_val.values.ravel()))\n",
    "\n",
    "# prediction and show contingency table\n",
    "ct = pd.crosstab(search.best_estimator_.predict(X_val), y_val.values.ravel(),\n",
    "                 rownames=[\"pred\"], colnames=[\"true\"])\n",
    "print(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': LogisticRegression(max_iter=30), 'model__C': 0.1, 'pca__n_components': 1} 0.49852431204246095\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 0.1, 'pca__n_components': 2} 0.5548233794447035\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 0.1, 'pca__n_components': 3} 0.8577070052468343\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 0.1, 'pca__n_components': 4} 0.8755678172121085\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 1, 'pca__n_components': 1} 0.4985160236048315\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 1, 'pca__n_components': 2} 0.5548233794447035\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 1, 'pca__n_components': 3} 0.857753106171345\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 1, 'pca__n_components': 4} 0.8759610205915616\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 10, 'pca__n_components': 1} 0.4985160236048315\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 10, 'pca__n_components': 2} 0.5548233794447035\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 10, 'pca__n_components': 3} 0.857753106171345\n",
      "{'model': LogisticRegression(max_iter=30), 'model__C': 10, 'pca__n_components': 4} 0.8759709777428242\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 10, 'pca__n_components': 1} 0.5\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 10, 'pca__n_components': 2} 0.916309391041289\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 10, 'pca__n_components': 3} 0.9209587373021245\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 10, 'pca__n_components': 4} 0.9742861299241865\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 20, 'pca__n_components': 1} 0.5\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 20, 'pca__n_components': 2} 0.9420924419740342\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 20, 'pca__n_components': 3} 0.9168447090223371\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 20, 'pca__n_components': 4} 0.9795793687110047\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 50, 'pca__n_components': 1} 0.5\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 50, 'pca__n_components': 2} 0.9461795648199463\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 50, 'pca__n_components': 3} 0.9283548910082375\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 2, 'model__n_estimators': 50, 'pca__n_components': 4} 0.9796039536784443\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 10, 'pca__n_components': 1} 0.5\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 10, 'pca__n_components': 2} 0.9532248682185465\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 10, 'pca__n_components': 3} 0.965991174331219\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 10, 'pca__n_components': 4} 0.9809161042143201\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 20, 'pca__n_components': 1} 0.5\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 20, 'pca__n_components': 2} 0.9548311155972783\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 20, 'pca__n_components': 3} 0.9668851827934901\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 20, 'pca__n_components': 4} 0.9797976666924892\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 50, 'pca__n_components': 1} 0.5\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 50, 'pca__n_components': 2} 0.9581103305382193\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 50, 'pca__n_components': 3} 0.9667677834872024\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 3, 'model__n_estimators': 50, 'pca__n_components': 4} 0.9797291360877045\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 10, 'pca__n_components': 1} 0.5\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 10, 'pca__n_components': 2} 0.9704719225737761\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 10, 'pca__n_components': 3} 0.9750353516405778\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 10, 'pca__n_components': 4} 0.9881239217025325\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 20, 'pca__n_components': 1} 0.5\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 20, 'pca__n_components': 2} 0.9728582238958209\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 20, 'pca__n_components': 3} 0.9787031837597239\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 20, 'pca__n_components': 4} 0.989178023919392\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 50, 'pca__n_components': 1} 0.5\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 50, 'pca__n_components': 2} 0.9727307376073437\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 50, 'pca__n_components': 3} 0.9772001249122276\n",
      "{'model': RandomForestClassifier(), 'model__max_depth': 4, 'model__n_estimators': 50, 'pca__n_components': 4} 0.9892892584888819\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 10, 'pca__n_components': 1} 0.5\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 10, 'pca__n_components': 2} 0.9829055868814551\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 10, 'pca__n_components': 3} 0.9865029633644726\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 10, 'pca__n_components': 4} 0.9865299010514509\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 20, 'pca__n_components': 1} 0.5\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 20, 'pca__n_components': 2} 0.9829906492249529\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 20, 'pca__n_components': 3} 0.9910407627184012\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 20, 'pca__n_components': 4} 0.990915370887036\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 30, 'pca__n_components': 1} 0.5102474026803964\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 30, 'pca__n_components': 2} 0.9829768675353792\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 30, 'pca__n_components': 3} 0.9946923745094999\n",
      "{'model': GradientBoostingClassifier(), 'model__n_estimators': 30, 'pca__n_components': 4} 0.9925840806949582\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# (optional, if you're curious) for a detailed look on the performance of the different models\n",
    "def get_search_score_overview():\n",
    "  for c,s in zip(search.cv_results_[\"params\"],search.cv_results_[\"mean_test_score\"]):\n",
    "      print(c, s)\n",
    "\n",
    "print(get_search_score_overview())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_diet_category</th>\n",
       "      <th>HighCalories_Requested</th>\n",
       "      <th>HighProtein_Requested</th>\n",
       "      <th>LowFat_Requested</th>\n",
       "      <th>RecipeCategory</th>\n",
       "      <th>Calories</th>\n",
       "      <th>FatContent</th>\n",
       "      <th>SodiumContent</th>\n",
       "      <th>CarbohydrateContent</th>\n",
       "      <th>ProteinContent</th>\n",
       "      <th>recipe_diet_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vegan</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vegan</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Omnivore</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>241.3</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.1</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140174</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Other</td>\n",
       "      <td>289.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1310.9</td>\n",
       "      <td>28.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>Omnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140185</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Other</td>\n",
       "      <td>242.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>305.4</td>\n",
       "      <td>36.4</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140186</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>391.0</td>\n",
       "      <td>23.4</td>\n",
       "      <td>589.5</td>\n",
       "      <td>32.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140188</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Other</td>\n",
       "      <td>325.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>969.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>Omnivore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140191</th>\n",
       "      <td>Vegetarian</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Other</td>\n",
       "      <td>652.2</td>\n",
       "      <td>25.8</td>\n",
       "      <td>435.5</td>\n",
       "      <td>51.9</td>\n",
       "      <td>50.1</td>\n",
       "      <td>Vegetarian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42814 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_diet_category  HighCalories_Requested  HighProtein_Requested  \\\n",
       "5                   Vegan                   False                   True   \n",
       "7              Vegetarian                   False                  False   \n",
       "8              Vegetarian                   False                  False   \n",
       "14                  Vegan                   False                   True   \n",
       "15               Omnivore                   False                   True   \n",
       "...                   ...                     ...                    ...   \n",
       "140174         Vegetarian                   False                  False   \n",
       "140185         Vegetarian                   False                   True   \n",
       "140186         Vegetarian                   False                   True   \n",
       "140188         Vegetarian                    True                   True   \n",
       "140191         Vegetarian                   False                   True   \n",
       "\n",
       "        LowFat_Requested RecipeCategory  Calories  FatContent  SodiumContent  \\\n",
       "5                  False          Other     241.3        10.1           13.1   \n",
       "7                  False          Other     241.3        10.1           13.1   \n",
       "8                  False          Other     241.3        10.1           13.1   \n",
       "14                 False          Other     241.3        10.1           13.1   \n",
       "15                 False          Other     241.3        10.1           13.1   \n",
       "...                  ...            ...       ...         ...            ...   \n",
       "140174              True          Other     289.3         8.6         1310.9   \n",
       "140185              True          Other     242.0         7.1          305.4   \n",
       "140186             False          Other     391.0        23.4          589.5   \n",
       "140188             False          Other     325.4        21.5          969.3   \n",
       "140191              True          Other     652.2        25.8          435.5   \n",
       "\n",
       "        CarbohydrateContent  ProteinContent recipe_diet_category  \n",
       "5                      31.8             6.7           Vegetarian  \n",
       "7                      31.8             6.7           Vegetarian  \n",
       "8                      31.8             6.7           Vegetarian  \n",
       "14                     31.8             6.7           Vegetarian  \n",
       "15                     31.8             6.7           Vegetarian  \n",
       "...                     ...             ...                  ...  \n",
       "140174                 28.9            16.7             Omnivore  \n",
       "140185                 36.4             8.4           Vegetarian  \n",
       "140186                 32.4            13.5           Vegetarian  \n",
       "140188                 20.0            13.4             Omnivore  \n",
       "140191                 51.9            50.1           Vegetarian  \n",
       "\n",
       "[42814 rows x 11 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare test data for prediction\n",
    "test_set_id = test_dataframe.pop('TestSetId')\n",
    "test_dataframe = test_dataframe.drop('Like', axis=1)\n",
    "test_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "model = search.best_estimator_ \n",
    "prediction = model.predict(test_dataframe)\n",
    "\n",
    "#TODO: \n",
    "\n",
    "# prediction := List if Like \n",
    "# test_set_id := List of test ID\n",
    "\n",
    "# write to CSV file in the same order  (den Code unten anpassenm)\n",
    "# 1.ID  1.Like \n",
    "# 2.ID  2.Like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42814\n"
     ]
    }
   ],
   "source": [
    "# Let's assume that our id column is the index of the dataframe\n",
    "\n",
    "# print(test_dataframe)\n",
    "#output = pd.DataFrame(test_dataframe[\"Like\"])\n",
    "# output = output.reset_index(drop=True)\n",
    "#output[\"id\"] = output.index + 1\n",
    "#output = output.rename(columns={'Like': 'prediction'})\n",
    "#output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "# output length\n",
    "#print(len(output))\n",
    "#output.to_csv('recipe_prediction.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
